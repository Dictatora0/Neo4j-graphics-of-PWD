#!/usr/bin/env python3
"""
çŸ¥è¯†å›¾è°±æ„å»ºå¯åŠ¨è„šæœ¬
æä¾›è¯¦ç»†çš„è¿è¡Œä¿¡æ¯ã€è¿›åº¦ç›‘æ§å’Œç¯å¢ƒæ£€æŸ¥
"""

import os
import sys
import time
import subprocess
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config_loader import load_config
from enhanced_pipeline_safe import run_safe_pipeline


def print_banner():
    """æ‰“å°æ¨ªå¹…"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                      â•‘
â•‘        æ¾æçº¿è™«ç—…çŸ¥è¯†å›¾è°±æ„å»ºç³»ç»Ÿ v2.5                                  â•‘
â•‘        Pine Wilt Disease Knowledge Graph Builder                    â•‘
â•‘                                                                      â•‘
â•‘        ç‰¹æ€§: LLMæŠ½å– | BGE-M3å»é‡ | æ–­ç‚¹ç»­ä¼  | å®‰å…¨ä¿æŠ¤                 â•‘
â•‘                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)


def check_environment():
    """ç¯å¢ƒæ£€æŸ¥"""
    print("\n" + "="*70)
    print(" ğŸ” ç¯å¢ƒæ£€æŸ¥")
    print("="*70)
    
    checks = []
    
    # æ£€æŸ¥ Python ç‰ˆæœ¬
    py_version = sys.version.split()[0]
    checks.append(("Python ç‰ˆæœ¬", py_version, True))
    
    # æ£€æŸ¥ Ollama æœåŠ¡
    try:
        result = subprocess.run(
            ["curl", "-s", "http://localhost:11434/api/tags"],
            capture_output=True,
            timeout=3
        )
        ollama_ok = result.returncode == 0
        checks.append(("Ollama æœåŠ¡", "è¿è¡Œä¸­" if ollama_ok else "æœªè¿è¡Œ", ollama_ok))
    except Exception as e:
        checks.append(("Ollama æœåŠ¡", f"æ£€æŸ¥å¤±è´¥: {e}", False))
        ollama_ok = False
    
    # æ£€æŸ¥æ¨¡å‹
    config = load_config()
    model_name = config['llm']['model']
    
    if ollama_ok:
        try:
            result = subprocess.run(
                ["ollama", "list"],
                capture_output=True,
                text=True
            )
            has_model = model_name in result.stdout
            checks.append(("LLM æ¨¡å‹", model_name if has_model else f"{model_name} (æœªå®‰è£…)", has_model))
        except:
            checks.append(("LLM æ¨¡å‹", "æ£€æŸ¥å¤±è´¥", False))
            has_model = False
    else:
        checks.append(("LLM æ¨¡å‹", "æ— æ³•æ£€æŸ¥", False))
        has_model = False
    
    # æ£€æŸ¥ä¾èµ–åº“
    deps = [
        ("torch", "PyTorch"),
        ("sentence_transformers", "SentenceTransformers"),
        ("pandas", "Pandas"),
        ("tqdm", "tqdm"),
    ]
    
    for module, name in deps:
        try:
            __import__(module)
            checks.append((f"{name} åº“", "å·²å®‰è£…", True))
        except ImportError:
            checks.append((f"{name} åº“", "æœªå®‰è£…", False))
    
    # æ£€æŸ¥ PyTorch ç‰ˆæœ¬
    try:
        import torch
        torch_version = torch.__version__
        mps_available = torch.backends.mps.is_available()
        checks.append(("PyTorch ç‰ˆæœ¬", torch_version, True))
        checks.append(("Apple GPU (MPS)", "å¯ç”¨" if mps_available else "ä¸å¯ç”¨", mps_available))
    except:
        checks.append(("PyTorch", "æœªå®‰è£…", False))
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    pdf_dir = config.get('pdf.input_directory', './æ–‡çŒ®')
    pdf_files = list(Path(pdf_dir).glob("*.pdf")) if os.path.exists(pdf_dir) else []
    checks.append(("PDF æ–‡ä»¶", f"{len(pdf_files)} ä¸ª", len(pdf_files) > 0))
    
    # æ‰“å°æ£€æŸ¥ç»“æœ
    all_ok = True
    for name, status, ok in checks:
        icon = "âœ“" if ok else "âœ—"
        color = "\033[92m" if ok else "\033[91m"
        reset = "\033[0m"
        print(f"  {color}{icon}{reset} {name:<20} {status}")
        if not ok:
            all_ok = False
    
    print()
    return all_ok, has_model, model_name


def show_config_info():
    """æ˜¾ç¤ºé…ç½®ä¿¡æ¯"""
    print("="*70)
    print(" âš™ï¸  è¿è¡Œé…ç½®")
    print("="*70)
    
    config = load_config()
    
    # LLM é…ç½®
    print("\nğŸ“ LLM é…ç½®:")
    print(f"  â€¢ æ¨¡å‹: {config['llm']['model']}")
    print(f"  â€¢ ä¸»æœº: {config['llm']['ollama_host']}")
    print(f"  â€¢ å¤„ç†å—æ•°: {config['llm'].get('max_chunks', 'ALL')}")
    print(f"  â€¢ è¶…æ—¶æ—¶é—´: {config['llm']['timeout']} ç§’")
    print(f"  â€¢ ä¸Šä¸‹æ–‡çª—å£: {config['llm']['num_ctx']}")
    print(f"  â€¢ æ¸©åº¦: {config['llm']['temperature']}")
    
    # å»é‡é…ç½®
    print("\nğŸ”„ å»é‡é…ç½®:")
    use_bge = config['deduplication']['use_bge_m3']
    print(f"  â€¢ å¼•æ“: {'BGE-M3 (æ··åˆæ£€ç´¢)' if use_bge else 'MiniLM'}")
    if use_bge:
        print(f"  â€¢ æ¨¡å‹: {config['deduplication']['embedding_model']}")
        print(f"  â€¢ æ··åˆæƒé‡: {config['deduplication']['hybrid_alpha']}")
    print(f"  â€¢ ç›¸ä¼¼åº¦é˜ˆå€¼: {config['deduplication']['similarity_threshold']}")
    
    # è¿‡æ»¤é…ç½®
    print("\nğŸ¯ è¿‡æ»¤é…ç½®:")
    print(f"  â€¢ æœ€å°é‡è¦æ€§: {config['filtering']['min_importance']}")
    print(f"  â€¢ æœ€å°è¿æ¥æ•°: {config['filtering']['min_connections']}")
    
    # è¾“å…¥è¾“å‡º
    print("\nğŸ“ æ–‡ä»¶é…ç½®:")
    print(f"  â€¢ è¾“å…¥ç›®å½•: {config['pdf']['input_directory']}")
    print(f"  â€¢ è¾“å‡ºç›®å½•: {config['output']['base_directory']}")
    
    # å®‰å…¨ç‰¹æ€§
    print("\nğŸ”’ å®‰å…¨ç‰¹æ€§:")
    print(f"  â€¢ Checkpoint é—´éš”: 10 ä¸ªå—")
    print(f"  â€¢ æ–­ç‚¹ç»­ä¼ : å¯ç”¨")
    print(f"  â€¢ å¼‚å¸¸ä¿æŠ¤: å¯ç”¨")
    print(f"  â€¢ è¿›åº¦ä¿å­˜: output/checkpoints/")
    
    print()


def estimate_time():
    """ä¼°ç®—è¿è¡Œæ—¶é—´"""
    print("="*70)
    print(" â±ï¸  æ—¶é—´ä¼°ç®—")
    print("="*70)
    
    config = load_config()
    max_chunks = config['llm'].get('max_chunks', 100)
    
    # è¯»å–æµ‹è¯•ç»“æœä¼°ç®—
    time_per_chunk = 92  # 7B æ¨¡å‹çº¦ 92 ç§’/å—
    
    total_seconds = time_per_chunk * max_chunks if max_chunks else time_per_chunk * 100
    total_minutes = total_seconds / 60
    total_hours = total_minutes / 60
    
    print(f"\nåŸºäº {config['llm']['model']} æ¨¡å‹ä¼°ç®—:")
    print(f"  â€¢ å•å—è€—æ—¶: ~{time_per_chunk} ç§’")
    
    if max_chunks:
        print(f"  â€¢ å¤„ç†å—æ•°: {max_chunks} ä¸ª")
        print(f"  â€¢ é¢„è®¡æ€»è€—æ—¶: {total_minutes:.1f} åˆ†é’Ÿ ({total_hours:.1f} å°æ—¶)")
    else:
        print(f"  â€¢ å¤„ç†å—æ•°: ALLï¼ˆå–å†³äº PDF æ•°é‡ï¼‰")
        print(f"  â€¢ é¢„è®¡è€—æ—¶: ~{total_minutes:.1f} åˆ†é’Ÿï¼ˆ100å—ï¼‰")
    
    # é˜¶æ®µæ—¶é—´åˆ†å¸ƒ
    print(f"\nå„é˜¶æ®µæ—¶é—´åˆ†å¸ƒ:")
    print(f"  â€¢ PDF æå–: ~2-3 åˆ†é’Ÿ")
    print(f"  â€¢ æ–‡æœ¬åˆ†å—: <1 åˆ†é’Ÿ")
    print(f"  â€¢ LLM æŠ½å–: ~{total_minutes*0.9:.1f} åˆ†é’Ÿ (ä¸»è¦è€—æ—¶)")
    print(f"  â€¢ å»é‡è¿‡æ»¤: ~1-2 åˆ†é’Ÿ")
    print(f"  â€¢ ä¿å­˜ç»“æœ: <1 åˆ†é’Ÿ")
    
    print()


def show_progress_tips():
    """æ˜¾ç¤ºè¿›åº¦æŸ¥çœ‹æç¤º"""
    print("="*70)
    print(" ğŸ’¡ è¿›åº¦ç›‘æ§")
    print("="*70)
    
    print("""
åœ¨å¦ä¸€ä¸ªç»ˆç«¯çª—å£ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç›‘æ§è¿›åº¦:

1. å®æ—¶æŸ¥çœ‹æ—¥å¿—:
   tail -f output/kg_builder.log

2. æŸ¥çœ‹ checkpoint è¿›åº¦:
   cat output/checkpoints/.progress.json

3. æŸ¥çœ‹å·²ä¿å­˜çš„æ–‡ä»¶:
   ls -lh output/checkpoints/

4. æŸ¥çœ‹ç³»ç»Ÿèµ„æºä½¿ç”¨:
   top | grep python

æç¤º:
  â€¢ æ¯ 10 ä¸ªå—ä¼šçœ‹åˆ° "âœ“ Checkpoint: X/Y chunks processed"
  â€¢ å¯éšæ—¶æŒ‰ Ctrl+C å®‰å…¨é€€å‡ºï¼ˆä¼šè‡ªåŠ¨ä¿å­˜è¿›åº¦ï¼‰
  â€¢ é‡æ–°è¿è¡Œä¼šè‡ªåŠ¨ä»æ–­ç‚¹ç»§ç»­
    """)
    print("="*70)


def run_with_monitoring():
    """è¿è¡Œç®¡é“å¹¶ç›‘æ§"""
    print("\n" + "="*70)
    print(" ğŸš€ å¯åŠ¨çŸ¥è¯†å›¾è°±æ„å»º")
    print("="*70)
    
    start_time = datetime.now()
    print(f"\nå¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("\næ­£åœ¨è¿è¡Œ...")
    print("æç¤º: æŒ‰ Ctrl+C å¯å®‰å…¨é€€å‡ºå¹¶ä¿å­˜è¿›åº¦\n")
    print("-"*70 + "\n")
    
    try:
        # è¿è¡Œç®¡é“
        concepts_df, relationships_df = run_safe_pipeline(
            resume=True,
            clear_checkpoint=False
        )
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        # æ˜¾ç¤ºç»“æœ
        print("\n" + "="*70)
        print(" âœ… æ„å»ºå®Œæˆ")
        print("="*70)
        
        print(f"\nç»“æŸæ—¶é—´: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æ€»è€—æ—¶: {duration}")
        
        print(f"\nğŸ“Š ç»“æœç»Ÿè®¡:")
        print(f"  â€¢ æ¦‚å¿µæ€»æ•°: {len(concepts_df)}")
        print(f"  â€¢ å…³ç³»æ€»æ•°: {len(relationships_df)}")
        
        if not concepts_df.empty:
            print(f"\nğŸ† TOP 10 é‡è¦æ¦‚å¿µ:")
            top_concepts = concepts_df.nlargest(10, 'importance')
            for idx, (_, row) in enumerate(top_concepts.iterrows(), 1):
                print(f"  {idx:2d}. {row['entity']:<30} (é‡è¦æ€§: {row.get('importance', 0):.1f})")
        
        if not relationships_df.empty:
            print(f"\nğŸ”— TOP 5 é«˜æƒé‡å…³ç³»:")
            top_rels = relationships_df.nlargest(5, 'weight')
            for idx, (_, row) in enumerate(top_rels.iterrows(), 1):
                print(f"  {idx}. {row['node_1']} --[{row['edge']}]-> {row['node_2']} ({row['weight']:.2f})")
        
        # è¾“å‡ºæ–‡ä»¶
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  â€¢ æ¦‚å¿µæ–‡ä»¶: output/concepts.csv")
        print(f"  â€¢ å…³ç³»æ–‡ä»¶: output/relationships.csv")
        print(f"  â€¢ æ—¥å¿—æ–‡ä»¶: output/kg_builder.log")
        print(f"  â€¢ Checkpoint: output/checkpoints/")
        
        print("\n" + "="*70)
        print(" ğŸ‰ çŸ¥è¯†å›¾è°±æ„å»ºæˆåŠŸï¼")
        print("="*70 + "\n")
        
        return True
        
    except KeyboardInterrupt:
        print("\n\n" + "="*70)
        print(" âš ï¸  ç”¨æˆ·ä¸­æ–­")
        print("="*70)
        print("\nâœ“ è¿›åº¦å·²è‡ªåŠ¨ä¿å­˜åˆ°: output/checkpoints/")
        print("\nè¦ç»§ç»­å¤„ç†ï¼Œè¯·é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        print("\n" + "="*70 + "\n")
        return False
        
    except Exception as e:
        print("\n\n" + "="*70)
        print(f" âŒ å‘ç”Ÿé”™è¯¯")
        print("="*70)
        print(f"\né”™è¯¯ä¿¡æ¯: {e}")
        print("\nâœ“ å·²å¤„ç†çš„æ•°æ®å·²ä¿å­˜ï¼ˆå¦‚æœæœ‰ï¼‰")
        print("\næŸ¥çœ‹è¯¦ç»†æ—¥å¿—: output/kg_builder.log")
        print("\n" + "="*70 + "\n")
        
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•°"""
    # æ‰“å°æ¨ªå¹…
    print_banner()
    
    # ç¯å¢ƒæ£€æŸ¥
    env_ok, has_model, model_name = check_environment()
    
    if not env_ok:
        print("âš ï¸  ç¯å¢ƒæ£€æŸ¥å‘ç°é—®é¢˜ï¼Œè¯·å…ˆè§£å†³ä¸Šè¿°é—®é¢˜å†è¿è¡Œ")
        
        # æä¾›è§£å†³å»ºè®®
        print("\n" + "="*70)
        print(" ğŸ”§ è§£å†³å»ºè®®")
        print("="*70)
        print("""
å¦‚æœ Ollama æœåŠ¡æœªè¿è¡Œ:
  ollama serve

å¦‚æœæ¨¡å‹æœªå®‰è£…:
  ollama pull qwen2.5-coder:7b

å¦‚æœä¾èµ–åº“ç¼ºå¤±:
  pip install -r requirements.txt
        """)
        print("="*70 + "\n")
        sys.exit(1)
    
    # æ˜¾ç¤ºé…ç½®
    show_config_info()
    
    # æ—¶é—´ä¼°ç®—
    estimate_time()
    
    # è¿›åº¦ç›‘æ§æç¤º
    show_progress_tips()
    
    # ç¡®è®¤å¼€å§‹
    print("\n" + "="*70)
    print(" âš¡ å‡†å¤‡å°±ç»ª")
    print("="*70)
    print("\næŒ‰ Enter å¼€å§‹è¿è¡Œï¼Œæˆ–æŒ‰ Ctrl+C å–æ¶ˆ...")
    
    try:
        input()
    except KeyboardInterrupt:
        print("\n\nå·²å–æ¶ˆ\n")
        sys.exit(0)
    
    # è¿è¡Œç®¡é“
    success = run_with_monitoring()
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
