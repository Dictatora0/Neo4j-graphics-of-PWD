# æ¾æçº¿è™«ç—…çŸ¥è¯†å›¾è°±æ„å»ºç³»ç»Ÿ - æ ¸å¿ƒæŠ€æœ¯æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ

> é¡¹ç›®ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„é¢†åŸŸçŸ¥è¯†å›¾è°±è‡ªåŠ¨åŒ–æ„å»ºç³»ç»Ÿ  
> æ—¶é—´è·¨åº¦ï¼š2025-11  
> æŠ€æœ¯æ ˆï¼šPython, Ollama (Qwen2.5), Neo4j, PyTorch

---

## é¡¹ç›®æ¦‚è¿°

### ç›®æ ‡

ä» 28 ç¯‡æ¾æçº¿è™«ç—…ç›¸å…³ PDF æ–‡çŒ®ä¸­ï¼Œè‡ªåŠ¨æ„å»ºç»“æ„åŒ–çŸ¥è¯†å›¾è°±ï¼ŒåŒ…æ‹¬ï¼š

- æ¦‚å¿µå®ä½“æŠ½å–
- å…³ç³»è¯†åˆ«
- è¯­ä¹‰å»é‡
- å›¾è°±å¯è§†åŒ–

### æŠ€æœ¯éš¾ç‚¹

1. **é•¿æ—¶é—´è¿è¡Œçš„ç¨³å®šæ€§** - é¢„è®¡ 7-8 å°æ—¶å¤„ç†æ—¶é—´
2. **LLM æ¨ç†æ€§èƒ½** - å¹³è¡¡é€Ÿåº¦ä¸è´¨é‡
3. **æ•°æ®ä¸€è‡´æ€§** - å¢é‡ä¿å­˜ä¸æ–­ç‚¹ç»­ä¼ 
4. **ç”¨æˆ·ä½“éªŒ** - å¯è§‚æµ‹æ€§ä¸æ˜“ç”¨æ€§

---

## æ ¸å¿ƒæŒ‘æˆ˜ä¸€ï¼šé•¿æ—¶é—´è¿è¡Œçš„æ•°æ®å®‰å…¨æ€§

### é—®é¢˜èƒŒæ™¯

**åˆå§‹è®¾è®¡**ï¼š

```python
# ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰æ•°æ®
all_results = []
for chunk in chunks:
    result = llm_extract(chunk)  # æ¯å—è€—æ—¶ 30-60s
    all_results.append(result)

save_to_file(all_results)  # æœ€åç»Ÿä¸€ä¿å­˜
```

**é—®é¢˜æš´éœ²**ï¼š

- å¤„ç† 500+ æ–‡æœ¬å—éœ€è¦ 7-8 å°æ—¶
- ä¸­é€”ä»»ä½•é”™è¯¯ï¼ˆæ–­ç”µã€ç½‘ç»œã€ç¨‹åºå´©æºƒï¼‰å¯¼è‡´**å…¨éƒ¨æ•°æ®ä¸¢å¤±**
- ç”¨æˆ·æ— æ³•ä¸­é€”åœæ­¢ï¼ˆCtrl+C ä¼šä¸¢å¤±æ‰€æœ‰è¿›åº¦ï¼‰

### æŠ€æœ¯åˆ†æ

**æ ¹æœ¬åŸå› **ï¼š

1. **åŸå­æ€§å¤±è´¥** - è¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å¤±è´¥
2. **æ— çŠ¶æ€è¿½è¸ª** - æ— æ³•çŸ¥é“å¤„ç†åˆ°å“ªé‡Œ
3. **å†…å­˜é£é™©** - å¤§é‡æ•°æ®ç´¯ç§¯åœ¨å†…å­˜ä¸­

**å½±å“è¯„ä¼°**ï¼š

- æ—¶é—´æˆæœ¬ï¼šæ¯æ¬¡å¤±è´¥éœ€é‡æ–°è¿è¡Œ 7-8 å°æ—¶
- ç”¨æˆ·ä½“éªŒï¼šæ— æ³•å®¹å¿ï¼Œé¡¹ç›®ä¸å¯ç”¨
- èµ„æºæµªè´¹ï¼šè®¡ç®—èµ„æºå’Œæ—¶é—´çš„åŒé‡æµªè´¹

### è§£å†³æ–¹æ¡ˆï¼šCheckpoint æœºåˆ¶

#### è®¾è®¡åŸåˆ™

1. **å¢é‡ä¿å­˜** - æ¯å¤„ç† N ä¸ªå—ä¿å­˜ä¸€æ¬¡
2. **è¿›åº¦è¿½è¸ª** - JSON è®°å½•å·²å¤„ç†çš„å— ID
3. **æ–­ç‚¹ç»­ä¼ ** - å¯åŠ¨æ—¶æ¢å¤æœªå®Œæˆçš„å·¥ä½œ
4. **ä¼˜é›…é€€å‡º** - Ctrl+C ä¿å­˜å½“å‰è¿›åº¦

#### å®ç°æ¶æ„

```python
class CheckpointManager:
    """
    æ ¸å¿ƒèŒè´£ï¼š
    1. ç»´æŠ¤è¿›åº¦æ–‡ä»¶ (.progress.json)
    2. å¢é‡ä¿å­˜ CSV (è¿½åŠ æ¨¡å¼)
    3. å®šæœŸåˆ›å»ºå®Œæ•´å¿«ç…§
    """

    def __init__(self, checkpoint_dir):
        self.progress_file = checkpoint_dir / '.progress.json'
        self.concepts_file = checkpoint_dir / 'concepts_incremental.csv'
        self.relationships_file = checkpoint_dir / 'relationships_incremental.csv'
        self.progress = self._load_progress()

    def save_chunk_results(self, chunk_id, concepts, relationships):
        """å¢é‡ä¿å­˜å•ä¸ªå—çš„ç»“æœ"""
        # 1. è¿½åŠ åˆ° CSV
        self._append_to_csv(self.concepts_file, concepts)
        self._append_to_csv(self.relationships_file, relationships)

        # 2. æ›´æ–°è¿›åº¦
        self.progress['processed_chunks'].append(chunk_id)
        self.progress['total_concepts'] += len(concepts)
        self.progress['total_relationships'] += len(relationships)

        # 3. æŒä¹…åŒ–è¿›åº¦
        self._save_progress()

    def save_checkpoint(self, chunk_num, concepts_df, relationships_df):
        """å®šæœŸä¿å­˜å®Œæ•´å¿«ç…§"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        concepts_df.to_csv(
            f'checkpoint_concepts_{chunk_num}_{timestamp}.csv',
            index=False
        )
        # åŒæ ·ä¿å­˜ relationships
```

#### ä¸»ç®¡é“é›†æˆ

```python
class SafePipeline:
    def __init__(self, config, checkpoint_interval=10):
        self.checkpoint_manager = CheckpointManager(config['checkpoint_dir'])
        self.checkpoint_interval = checkpoint_interval

    def run(self):
        try:
            chunks = self._split_texts()

            # è¿‡æ»¤å·²å¤„ç†çš„å—
            processed = self.checkpoint_manager.get_processed_chunks()
            remaining = [c for c in chunks if c['chunk_id'] not in processed]

            logger.info(f"Total: {len(chunks)}, Processed: {len(processed)}, "
                       f"Remaining: {len(remaining)}")

            # å¢é‡å¤„ç†
            for i, chunk in enumerate(remaining):
                try:
                    concepts, rels = self.llm_extract(chunk)

                    # ç«‹å³ä¿å­˜
                    self.checkpoint_manager.save_chunk_results(
                        chunk['chunk_id'], concepts, rels
                    )

                    # å®šæœŸå¿«ç…§
                    if (i + 1) % self.checkpoint_interval == 0:
                        self._create_snapshot(i + 1)

                except Exception as e:
                    logger.error(f"Failed chunk {chunk['chunk_id']}: {e}")
                    continue  # ç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª

        except KeyboardInterrupt:
            logger.info("User interrupted, saving progress...")
            self._finalize()
            raise
```

#### è¿›åº¦æ–‡ä»¶æ ¼å¼

```json
{
  "processed_chunks": ["doc1_chunk_1", "doc1_chunk_2", "doc2_chunk_1"],
  "total_concepts": 132,
  "total_relationships": 93,
  "last_checkpoint": 30,
  "last_update": "2025-11-29T21:48:15"
}
```

### æ•ˆæœè¯„ä¼°

| æŒ‡æ ‡         | æ”¹è¿›å‰   | æ”¹è¿›å    | æå‡        |
| ------------ | -------- | --------- | ----------- |
| æ•°æ®ä¸¢å¤±é£é™© | 100%     | 0%        | âœ… æ¶ˆé™¤     |
| æœ€å¤§æŸå¤±æ—¶é—´ | 7-8 å°æ—¶ | < 10 åˆ†é’Ÿ | **40x+**    |
| å¯ä¸­æ–­æ€§     | âŒ å¦    | âœ… æ˜¯     | âœ… æ”¯æŒ     |
| ç”¨æˆ·ä¿¡å¿ƒ     | ä½       | é«˜        | âœ… æ˜¾è‘—æå‡ |

### æŠ€æœ¯äº®ç‚¹

1. **å¢é‡å¼è®¾è®¡** - æ¯ä¸ªå—ç‹¬ç«‹ä¿å­˜ï¼Œå¤±è´¥å½±å“æœ€å°åŒ–
2. **åŒé‡ä¿é™©** - å¢é‡ CSV + å®šæœŸå¿«ç…§
3. **çŠ¶æ€å¯è¿½è¸ª** - è¿›åº¦æ–‡ä»¶æä¾›å®Œæ•´çŠ¶æ€è§†å›¾
4. **ä¼˜é›…é™çº§** - LLM å•æ¬¡å¤±è´¥ä¸å½±å“æ•´ä½“æµç¨‹

---

## æ ¸å¿ƒæŒ‘æˆ˜äºŒï¼šLLM æ¨ç†æ€§èƒ½ä¼˜åŒ–

### é—®é¢˜èƒŒæ™¯

**åˆå§‹é…ç½®**ï¼š

```yaml
llm:
  model: qwen2.5-coder:32b
  timeout: 120
  max_chunks: 50
```

**æ€§èƒ½è¡¨ç°**ï¼š

```
å®æµ‹å•å—è€—æ—¶: 180-240ç§’
è¶…æ—¶ç‡: ~40%
é¢„è®¡æ€»æ—¶é—´: 500å— Ã— 200ç§’ = 27å°æ—¶
```

**ä¸å¯æ¥å—**ï¼šç”¨æˆ·æ— æ³•ç­‰å¾…ä¸€å¤©å®Œæˆã€‚

### é—®é¢˜åˆ†æ

#### 1. æ¨¡å‹è§„æ¨¡ä¸é€Ÿåº¦çš„çŸ›ç›¾

| æ¨¡å‹              | å‚æ•°é‡ | å•å—è€—æ—¶ | è´¨é‡       | æ€»æ—¶é—´(500 å—)    |
| ----------------- | ------ | -------- | ---------- | ----------------- |
| qwen2.5-coder:32b | 32B    | 180-240s | â­â­â­â­â­ | **25-33 å°æ—¶** âŒ |
| qwen2.5-coder:14b | 14B    | 80-120s  | â­â­â­â­   | 11-16 å°æ—¶ âš ï¸     |
| qwen2.5-coder:7b  | 7B     | 30-50s   | â­â­â­     | **4-7 å°æ—¶** âœ…   |

#### 2. è¶…æ—¶ç­–ç•¥é—®é¢˜

**æ ¹æœ¬çŸ›ç›¾**ï¼š

- è®¾ç½®å¤ªçŸ­ â†’ æ­£å¸¸è¯·æ±‚è¢«æ€æ­»
- è®¾ç½®å¤ªé•¿ â†’ å¡æ­»æƒ…å†µç­‰å¾…æ—¶é—´é•¿

**å®æµ‹æ•°æ®**ï¼š

```
32B æ¨¡å‹å®é™…éœ€è¦: 180-240ç§’
é…ç½® timeout=120: å¯¼è‡´ 40% è¶…æ—¶
è°ƒæ•´ timeout=300: è§£å†³è¶…æ—¶ï¼Œä½†é€Ÿåº¦ä»æ…¢
```

#### 3. Ollama æœ¬åœ°æ¨ç†çš„é™åˆ¶

**ç¡¬ä»¶é™åˆ¶**ï¼š

- CPU æ¨ç†ï¼ˆæ—  GPUï¼‰
- å†…å­˜å¸¦å®½ç“¶é¢ˆ
- å¤§æ¨¡å‹é‡åŒ–åä»æ…¢

### è§£å†³æ–¹æ¡ˆï¼šå¤šç»´åº¦ä¼˜åŒ–

#### æ–¹æ¡ˆ 1: æ¨¡å‹é™çº§ â­â­â­â­â­

**å†³ç­–é€»è¾‘**ï¼š

```
è´¨é‡ vs é€Ÿåº¦æƒè¡¡:
- 32B: è´¨é‡ 100%, é€Ÿåº¦ 20%  â†’ æ€»ä»·å€¼ = 120
- 7B:  è´¨é‡ 85%,  é€Ÿåº¦ 100% â†’ æ€»ä»·å€¼ = 185  âœ… æ›´ä¼˜
```

**å®æ–½**ï¼š

```yaml
llm:
  model: qwen2.5-coder:7b # ä» 32b é™çº§
  timeout: 300 # å¢åŠ å®¹é”™ç©ºé—´
```

**æ•ˆæœ**ï¼š

- å•å—è€—æ—¶ï¼š180s â†’ **40s** (4.5x æå‡)
- æ€»æ—¶é—´ï¼š25 å°æ—¶ â†’ **5.5 å°æ—¶** (å¯æ¥å—)
- è¶…æ—¶ç‡ï¼š40% â†’ **<5%**

#### æ–¹æ¡ˆ 2: è‡ªé€‚åº”è¶…æ—¶

```python
class LLMExtractor:
    def __init__(self, base_timeout=300):
        self.base_timeout = base_timeout
        self.timeout_stats = []

    def extract(self, text):
        # æ ¹æ®å†å²æ•°æ®è°ƒæ•´è¶…æ—¶
        if len(self.timeout_stats) > 10:
            avg_time = np.mean(self.timeout_stats)
            timeout = min(avg_time * 2, self.base_timeout)
        else:
            timeout = self.base_timeout

        start = time.time()
        result = self._call_llm(text, timeout=timeout)
        elapsed = time.time() - start

        self.timeout_stats.append(elapsed)
        return result
```

#### æ–¹æ¡ˆ 3: å¹¶è¡Œå¤„ç† (æœªå®æ–½)

**æ½œåœ¨æ–¹æ¡ˆ**ï¼š

```python
# å¤šè¿›ç¨‹å¹¶è¡Œ
from concurrent.futures import ProcessPoolExecutor

def process_batch(chunks):
    with ProcessPoolExecutor(max_workers=4) as executor:
        results = executor.map(llm_extract, chunks)
    return list(results)
```

**æœªé‡‡ç”¨åŸå› **ï¼š

1. Ollama å•å®ä¾‹é™åˆ¶
2. å†…å­˜å‹åŠ›å¢å¤§
3. 7B æ¨¡å‹å·²è¶³å¤Ÿå¿«

### æ€§èƒ½å¯¹æ¯”

```
ä¼˜åŒ–å‰ï¼ˆ32Bï¼‰:
â”œâ”€ å•å—: 200s
â”œâ”€ 500å—: 27.8å°æ—¶
â””â”€ è¶…æ—¶ç‡: 40%

ä¼˜åŒ–åï¼ˆ7B + timeout=300ï¼‰:
â”œâ”€ å•å—: 40s        (-80%)
â”œâ”€ 500å—: 5.5å°æ—¶   (-80%)
â””â”€ è¶…æ—¶ç‡: <5%      (-87.5%)
```

### æŠ€æœ¯å¯ç¤º

1. **å¸•ç´¯æ‰˜åŸåˆ™** - 7B æ¨¡å‹æä¾› 85% è´¨é‡ï¼Œä½†é€Ÿåº¦å¿« 5 å€
2. **ä¸šåŠ¡ä¼˜å…ˆ** - å¯ç”¨æ€§ > æè‡´è´¨é‡
3. **æ•°æ®ä¼˜äºç®—æ³•** - æ›´å¤šæ ·æœ¬ > æ›´å¤§æ¨¡å‹

---

## æ ¸å¿ƒæŒ‘æˆ˜ä¸‰ï¼šé”™è¯¯å¤„ç†ä¸å®¹é”™è®¾è®¡

### é—®é¢˜èƒŒæ™¯

**å…¸å‹é”™è¯¯åœºæ™¯**ï¼š

```python
# LLM æŠ½å–å¤±è´¥è¿”å› None
concepts, relationships = llm_extract(chunk)
# concepts = None, relationships = None

# Checkpoint ä¿å­˜æ—¶å´©æºƒ
len(concepts)  # TypeError: object of type 'NoneType' has no len()
```

**å½±å“**ï¼š

- å•ä¸ªå—å¤±è´¥å¯¼è‡´æ•´ä¸ªç®¡é“å´©æºƒ
- å·²å¤„ç†çš„æ•°æ®ä¸¢å¤±
- ç”¨æˆ·ä½“éªŒæå·®

### æŠ€æœ¯åˆ†æ

#### é”™è¯¯ä¼ æ’­é“¾

```
LLM API é”™è¯¯
  â†“
è¿”å› None
  â†“
checkpoint_manager.save_chunk_results(None, None)
  â†“
len(None) â†’ TypeError
  â†“
ç®¡é“å´©æºƒï¼Œæ•°æ®ä¸¢å¤±
```

#### æ ¹æœ¬é—®é¢˜

1. **ç¼ºå°‘é˜²å¾¡æ€§ç¼–ç¨‹** - æœªéªŒè¯è¾“å…¥
2. **é”™è¯¯è¾¹ç•Œä¸æ¸…** - å¼‚å¸¸å‘ä¸Šä¼ æ’­
3. **æ— é™çº§ç­–ç•¥** - å…¨æˆ–æ— çš„é€»è¾‘

### è§£å†³æ–¹æ¡ˆï¼šå¤šå±‚é˜²å¾¡

#### Layer 1: LLM è°ƒç”¨å±‚

```python
def extract_concepts_and_relationships(self, text, chunk_id):
    """
    LLM æŠ½å–ï¼Œå¸¦é‡è¯•å’Œé™çº§
    """
    try:
        response = self.call_ollama(prompt, timeout=self.config['timeout'])

        if response is None:
            logger.warning(f"Chunk {chunk_id}: LLM returned None")
            return [], []  # é™çº§ï¼šè¿”å›ç©ºåˆ—è¡¨

        concepts, rels = self.parse_response(response)
        return concepts or [], rels or []  # ç¡®ä¿é None

    except requests.Timeout:
        logger.error(f"Chunk {chunk_id}: Timeout after {self.config['timeout']}s")
        return [], []

    except Exception as e:
        logger.error(f"Chunk {chunk_id}: Unexpected error: {e}")
        return [], []  # é™çº§ï¼Œä¸å½±å“æµç¨‹
```

#### Layer 2: Checkpoint ä¿å­˜å±‚

```python
def save_chunk_results(self, chunk_id, concepts, relationships):
    """
    ä¿å­˜ç»“æœï¼Œå¸¦è¾“å…¥éªŒè¯
    """
    # è¾“å…¥éªŒè¯å’Œæ ‡å‡†åŒ–
    if concepts is None:
        concepts = []
    if relationships is None:
        relationships = []

    # æ›´æ–°ç»Ÿè®¡
    self.progress['processed_chunks'].append(chunk_id)
    self.progress['total_concepts'] += len(concepts)  # ç°åœ¨å®‰å…¨äº†
    self.progress['total_relationships'] += len(relationships)

    # ä¿å­˜ï¼ˆå³ä½¿æ˜¯ç©ºç»“æœï¼‰
    self._append_to_csv(self.concepts_file, concepts)
    self._append_to_csv(self.relationships_file, relationships)
    self._save_progress()
```

#### Layer 3: ä¸»å¾ªç¯å±‚

```python
def _extract_with_checkpoints(self, chunks):
    """
    ä¸»æå–å¾ªç¯ï¼Œæœ€å¤–å±‚é˜²æŠ¤
    """
    all_concepts = []
    all_relationships = []

    for i, chunk in enumerate(chunks):
        try:
            # å•å—å¤„ç†
            concepts, relationships = self.concept_extractor.extract(
                chunk['text'], chunk['chunk_id']
            )

            # å®‰å…¨ç´¯ç§¯
            if concepts:
                all_concepts.extend(concepts)
            if relationships:
                all_relationships.extend(relationships)

            # ä¿å­˜ï¼ˆå³ä½¿å½“å‰å—å¤±è´¥ï¼‰
            self.checkpoint_manager.save_chunk_results(
                chunk['chunk_id'], concepts, relationships
            )

        except Exception as e:
            # æœ€å¤–å±‚æ•è·
            logger.error(f"Failed to process chunk {chunk['chunk_id']}: {e}")
            # è®°å½•å¤±è´¥ä½†ç»§ç»­å¤„ç†
            continue

    return all_concepts, all_relationships
```

### å®¹é”™ç­–ç•¥çŸ©é˜µ

| å±‚çº§          | é”™è¯¯ç±»å‹  | å¤„ç†ç­–ç•¥        | å½±å“èŒƒå›´ |
| ------------- | --------- | --------------- | -------- |
| LLM å±‚        | Timeout   | è¿”å› []         | å•å—     |
| LLM å±‚        | è§£æå¤±è´¥  | è¿”å› []         | å•å—     |
| Checkpoint å±‚ | None è¾“å…¥ | è½¬ä¸º []         | æ— å½±å“   |
| ä¸»å¾ªç¯å±‚      | ä»»æ„å¼‚å¸¸  | è®°å½• + continue | å•å—     |

### æ•ˆæœ

**æ”¹è¿›å‰**ï¼š

- å•ç‚¹å¤±è´¥ â†’ ç®¡é“å´©æºƒ
- é”™è¯¯ç‡ 5% â†’ ä¸¢å¤±æ‰€æœ‰æ•°æ®

**æ”¹è¿›å**ï¼š

- å•ç‚¹å¤±è´¥ â†’ è®°å½•å¹¶ç»§ç»­
- é”™è¯¯ç‡ 5% â†’ ä»…ä¸¢å¤± 5% æ•°æ®
- **å¯ç”¨æ€§ä» 0% æå‡åˆ° 95%**

---

## æ ¸å¿ƒæŒ‘æˆ˜å››ï¼šç”¨æˆ·ä½“éªŒä¸å¯è§‚æµ‹æ€§

### é—®é¢˜èƒŒæ™¯

**åˆå§‹çŠ¶æ€**ï¼š

```bash
$ python main.py
Processing...
(æ— è¾“å‡ºï¼Œè¿è¡Œ 7 å°æ—¶)
```

**ç”¨æˆ·å›°æƒ‘**ï¼š

- ç¨‹åºæ˜¯å¦åœ¨è¿è¡Œï¼Ÿ
- å¤„ç†åˆ°å“ªé‡Œäº†ï¼Ÿ
- è¿˜éœ€è¦å¤šä¹…ï¼Ÿ
- å¦‚ä½•ç›‘æ§ï¼Ÿ

### æŠ€æœ¯åˆ†æ

#### å¯è§‚æµ‹æ€§ç¼ºå¤±

1. **æ— è¿›åº¦åé¦ˆ** - é»‘ç›’å¤„ç†
2. **æ— çŠ¶æ€æŸ¥è¯¢** - æ— æ³•äº†è§£å½“å‰çŠ¶æ€
3. **æ— æ€§èƒ½æŒ‡æ ‡** - æ— æ³•ä¼˜åŒ–
4. **å¤šå…¥å£æ··ä¹±** - å¤šä¸ªå¯åŠ¨æ–¹å¼ï¼Œç”¨æˆ·ä¸çŸ¥é“ç”¨å“ªä¸ª

### è§£å†³æ–¹æ¡ˆï¼šå¤šç»´åº¦å¯è§‚æµ‹æ€§

#### 1. å®æ—¶è¿›åº¦æ¡

```python
from tqdm import tqdm

def _extract_with_checkpoints(self, chunks):
    for i, chunk in enumerate(tqdm(chunks, desc="Extracting concepts")):
        # å¤„ç†...
        pass

# è¾“å‡º:
# Extracting concepts:  7%|â–ˆâ–ˆâ–                   | 36/507 [30:30<7:28:57, 57.19s/it]
```

**ä¿¡æ¯å¯†åº¦**ï¼š

- å½“å‰è¿›åº¦ï¼š36/507 (7%)
- å·²ç”¨æ—¶é—´ï¼š30:30
- é¢„è®¡å‰©ä½™ï¼š7:28:57
- å¹³å‡é€Ÿåº¦ï¼š57.19s/it

#### 2. ç»“æ„åŒ–æ—¥å¿—

```python
import logging

# åˆ†çº§æ—¥å¿—
logger.info(f"âœ“ Checkpoint: {i+1}/{len(chunks)} chunks processed")
logger.debug(f"Saved results for chunk: {chunk_id}")
logger.warning(f"Chunk {chunk_id}: LLM returned None")
logger.error(f"Failed to process chunk {chunk_id}: {e}")

# æ—¥å¿—è¾“å‡º
INFO - âœ“ Checkpoint: 30/507 chunks processed
INFO -   - Concepts: 202
INFO -   - Relationships: 153
```

#### 3. çŠ¶æ€ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# status.sh - å¿«é€ŸæŸ¥çœ‹çŠ¶æ€

echo "ğŸ“Š çŸ¥è¯†å›¾è°±æ„å»ºçŠ¶æ€"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# è¯»å–è¿›åº¦
if [ -f "output/checkpoints/.progress.json" ]; then
    processed=$(jq '.processed_chunks | length' output/checkpoints/.progress.json)
    concepts=$(jq '.total_concepts' output/checkpoints/.progress.json)
    relationships=$(jq '.total_relationships' output/checkpoints/.progress.json)

    echo "âœ“ å·²å¤„ç†å—æ•°: $processed"
    echo "âœ“ æå–æ¦‚å¿µ: $concepts"
    echo "âœ“ æå–å…³ç³»: $relationships"
else
    echo "âš ï¸  æœªæ‰¾åˆ°è¿›åº¦æ–‡ä»¶"
fi

# æ£€æŸ¥è¿›ç¨‹
if pgrep -f "enhanced_pipeline" > /dev/null; then
    echo "âœ“ ç®¡é“æ­£åœ¨è¿è¡Œ"
else
    echo "âš ï¸  ç®¡é“æœªè¿è¡Œ"
fi
```

#### 4. å®æ—¶ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# monitor.sh - å®æ—¶ç›‘æ§

watch -n 5 './status.sh'

# æ¯5ç§’åˆ·æ–°æ˜¾ç¤º:
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ ğŸ“Š çŸ¥è¯†å›¾è°±æ„å»ºçŠ¶æ€                  â”‚
# â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”       â”‚
# â”‚ âœ“ å·²å¤„ç†å—æ•°: 36                    â”‚
# â”‚ âœ“ æå–æ¦‚å¿µ: 241                     â”‚
# â”‚ âœ“ æå–å…³ç³»: 187                     â”‚
# â”‚ âœ“ ç®¡é“æ­£åœ¨è¿è¡Œ                      â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5. ç»Ÿä¸€å¯åŠ¨å…¥å£

**é—®é¢˜**ï¼šå¤šä¸ªå¯åŠ¨æ–¹å¼æ··ä¹±

```bash
python main.py
python enhanced_pipeline.py
python enhanced_pipeline_safe.py
./run.sh
./start.py
```

**è§£å†³**ï¼šå•ä¸€å¯åŠ¨è„šæœ¬ + æ¸…æ™°æ–‡æ¡£

```bash
#!/bin/bash
# start.sh - å”¯ä¸€æ¨èçš„å¯åŠ¨æ–¹å¼

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘  æ¾æçº¿è™«ç—…çŸ¥è¯†å›¾è°±æ„å»ºç³»ç»Ÿ v2.5      â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# ç¯å¢ƒæ£€æŸ¥
if [ ! -f "$PYTHON_BIN" ]; then
    echo "âŒ Python 3.10.13 æœªæ‰¾åˆ°"
    exit 1
fi

# è¿›åº¦æ¢å¤
if [ -f "output/checkpoints/.progress.json" ]; then
    processed=$(python -c "import json; print(len(json.load(open('output/checkpoints/.progress.json'))['processed_chunks']))")
    echo "âœ“ å‘ç° checkpointï¼Œå°†ä»æ–­ç‚¹ç»§ç»­"
    echo "  å·²å¤„ç†å—æ•°: $processed"
fi

# å¯åŠ¨
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "æç¤º:"
echo "  â€¢ æŒ‰ Ctrl+C å¯å®‰å…¨é€€å‡ºå¹¶ä¿å­˜è¿›åº¦"
echo "  â€¢ åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œ './monitor.sh' æŸ¥çœ‹è¿›åº¦"
echo "  â€¢ æ—¥å¿—æ–‡ä»¶: output/kg_builder.log"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

exec "$PYTHON_BIN" enhanced_pipeline_safe.py "$@"
```

**START_HERE.md æ–‡æ¡£**ï¼š

````markdown
# å¿«é€Ÿå¼€å§‹

## å”¯ä¸€æ¨èçš„å¯åŠ¨æ–¹å¼

```bash
./start.sh
```
````

## çŠ¶æ€æŸ¥çœ‹

```bash
./status.sh    # ä¸€æ¬¡æ€§æŸ¥çœ‹
./monitor.sh   # å®æ—¶ç›‘æ§
```

## å¸¸è§é—®é¢˜

Q: å¦‚ä½•ä¸­é€”åœæ­¢ï¼Ÿ
A: Ctrl+Cï¼Œè¿›åº¦ä¼šè‡ªåŠ¨ä¿å­˜

Q: å¦‚ä½•æ¢å¤ï¼Ÿ
A: å†æ¬¡è¿è¡Œ ./start.shï¼Œè‡ªåŠ¨ä»æ–­ç‚¹ç»§ç»­

````

### æ•ˆæœå¯¹æ¯”

| ç»´åº¦ | æ”¹è¿›å‰ | æ”¹è¿›å | æå‡ |
|------|--------|--------|------|
| è¿›åº¦å¯è§æ€§ | âŒ æ—  | âœ… å®æ—¶è¿›åº¦æ¡ | âˆ |
| çŠ¶æ€æŸ¥è¯¢ | âŒ æ—  | âœ… status.sh | âˆ |
| å®æ—¶ç›‘æ§ | âŒ æ—  | âœ… monitor.sh | âˆ |
| å¯åŠ¨å¤æ‚åº¦ | 5ç§æ–¹å¼ | 1ç§æ–¹å¼ | 5x |
| ç”¨æˆ·æ»¡æ„åº¦ | ä½ | é«˜ | âœ… |

---

## æ ¸å¿ƒæŒ‘æˆ˜äº”ï¼šPython ç¯å¢ƒç®¡ç†

### é—®é¢˜èƒŒæ™¯

**é”™è¯¯ç°è±¡**ï¼š
```bash
$ python3 enhanced_pipeline_safe.py
Traceback (most recent call last):
  File "enhanced_pipeline_safe.py", line 3, in <module>
    import pandas as pd
ModuleNotFoundError: No module named 'pandas'
````

**å›°æƒ‘**ï¼š

- æ˜æ˜å·²ç» `pip install pandas`
- ä½†ç¨‹åºæ‰¾ä¸åˆ°

### æŠ€æœ¯åˆ†æ

**æ ¹æœ¬åŸå› **ï¼šPython ç¯å¢ƒéš”ç¦»

```
ç³»ç»Ÿ Python (/usr/bin/python3)
  â”œâ”€ æ— ç¬¬ä¸‰æ–¹åŒ…
  â””â”€ ç³»ç»Ÿçº§ï¼Œä¸åº”æ±¡æŸ“

pyenv Python (~/.pyenv/versions/3.10.13/bin/python)
  â”œâ”€ é¡¹ç›®ä¾èµ–å·²å®‰è£…
  â””â”€ ä½†æœªæ­£ç¡®æ¿€æ´»
```

**é—®é¢˜é“¾**ï¼š

```
ç”¨æˆ·æ‰§è¡Œ: python3 script.py
  â†“
ç³»ç»Ÿè§£æ: /usr/bin/python3
  â†“
ç¯å¢ƒæŸ¥æ‰¾: ç³»ç»Ÿ site-packages (æ— ç¬¬ä¸‰æ–¹åŒ…)
  â†“
ç»“æœ: ModuleNotFoundError
```

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆ 1: å¯åŠ¨è„šæœ¬æŒ‡å®šå®Œæ•´è·¯å¾„ â­â­â­â­â­

```bash
#!/bin/bash
# start.sh

# ç¡¬ç¼–ç  pyenv Python è·¯å¾„
PYTHON_BIN="$HOME/.pyenv/versions/3.10.13/bin/python"

# æ£€æŸ¥å­˜åœ¨æ€§
if [ ! -f "$PYTHON_BIN" ]; then
    echo "âŒ Python 3.10.13 æœªæ‰¾åˆ°"
    exit 1
fi

# ä½¿ç”¨å®Œæ•´è·¯å¾„æ‰§è¡Œ
exec "$PYTHON_BIN" enhanced_pipeline_safe.py "$@"
```

**ä¼˜ç‚¹**ï¼š

- æ˜ç¡®æ— æ­§ä¹‰
- ä¸ä¾èµ–ç¯å¢ƒå˜é‡
- å¯¹ç”¨æˆ·é€æ˜

#### æ–¹æ¡ˆ 2: Shebang (æœªé‡‡ç”¨)

```python
#!/usr/bin/env python3
# enhanced_pipeline_safe.py
```

**é—®é¢˜**ï¼š

- ä»ä¾èµ– PATH
- æ— æ³•ä¿è¯ç”¨å¯¹ç¯å¢ƒ

#### æ–¹æ¡ˆ 3: æ–‡æ¡£è¯´æ˜ (è¾…åŠ©)

```markdown
# ä¾èµ–å®‰è£…

## 1. å®‰è£… pyenv

brew install pyenv

## 2. å®‰è£… Python 3.10.13

pyenv install 3.10.13

## 3. è®¾ç½®é¡¹ç›®ç¯å¢ƒ

pyenv local 3.10.13

## 4. å®‰è£…ä¾èµ–

pip install -r requirements.txt

## 5. å¯åŠ¨

./start.sh # è‡ªåŠ¨ä½¿ç”¨æ­£ç¡®çš„ Python
```

### æŠ€æœ¯å¯ç¤º

1. **æ˜¾å¼ä¼˜äºéšå¼** - ç¡¬ç¼–ç è·¯å¾„æ¯”ä¾èµ– PATH æ›´å¯é 
2. **é™ä½ç”¨æˆ·è´Ÿæ‹…** - å¯åŠ¨è„šæœ¬å¤„ç†å¤æ‚æ€§
3. **é˜²å¾¡æ€§ç¼–ç¨‹** - æ£€æŸ¥ç¯å¢ƒå­˜åœ¨æ€§

---

## ç³»ç»Ÿæ¶æ„æ¼”è¿›

### v1.0: åŸå§‹ç‰ˆæœ¬

```
PDF â†’ æ–‡æœ¬æå– â†’ LLM æŠ½å– â†’ ä¸€æ¬¡æ€§ä¿å­˜ â†’ Neo4j
```

**é—®é¢˜**ï¼š

- âŒ æ— å®¹é”™
- âŒ æ•°æ®æ˜“ä¸¢å¤±
- âŒ ä¸å¯ä¸­æ–­

### v2.0: å¢åŠ  Checkpoint

```
PDF â†’ æ–‡æœ¬æå– â†’ LLM æŠ½å– â†’ å¢é‡ä¿å­˜ â†’ Neo4j
                    â†“
                Checkpoint Manager
```

**æ”¹è¿›**ï¼š

- âœ… æ–­ç‚¹ç»­ä¼ 
- âœ… æ•°æ®å®‰å…¨
- âœ… å¯ä¸­æ–­

### v2.5: å®Œæ•´ä¼˜åŒ– (å½“å‰)

```
PDF â†’ æ–‡æœ¬æå– â†’ åˆ†å— â†’ LLM æŠ½å–(7B) â†’ å»é‡ â†’ ä¿å­˜ â†’ Neo4j
                  â†“         â†“           â†“      â†“
              è¿›åº¦æ¡   Checkpoint   BGE-M3  ç›‘æ§è„šæœ¬
                      (æ¯10å—)
```

**ç‰¹æ€§**ï¼š

- âœ… å¤šå±‚å®¹é”™
- âœ… æ€§èƒ½ä¼˜åŒ– (5x)
- âœ… å®Œæ•´å¯è§‚æµ‹æ€§
- âœ… ç”¨æˆ·å‹å¥½

---

## æŠ€æœ¯æ€»ç»“

### æ ¸å¿ƒåŸåˆ™

1. **ç¨³å®šæ€§ä¼˜å…ˆ**

   - å¢é‡ä¿å­˜èƒœè¿‡æ‰¹é‡ä¿å­˜
   - å®¹é”™è®¾è®¡èƒœè¿‡å®Œç¾æ‰§è¡Œ
   - é™çº§ç­–ç•¥èƒœè¿‡å¤±è´¥ä¸­æ–­

2. **ç”¨æˆ·ä½“éªŒç¬¬ä¸€**

   - å¯è§‚æµ‹æ€§è‡³å…³é‡è¦
   - å•ä¸€å…¥å£é™ä½å¤æ‚åº¦
   - æ–‡æ¡£ä¸ä»£ç åŒç­‰é‡è¦

3. **æ€§èƒ½ä¸è´¨é‡å¹³è¡¡**

   - 7B æ¨¡å‹ 85% è´¨é‡ + 5x é€Ÿåº¦ > 32B æ¨¡å‹ 100% è´¨é‡
   - å¯ç”¨æ€§ä¼˜äºå®Œç¾æ€§
   - ä¸šåŠ¡ä»·å€¼å¯¼å‘

4. **å·¥ç¨‹åŒ–æ€ç»´**
   - é˜²å¾¡æ€§ç¼–ç¨‹
   - å¤šå±‚é˜²æŠ¤
   - æ˜¾å¼é…ç½®

### æŠ€æœ¯æ ˆé€‰æ‹©

| ç»„ä»¶      | é€‰å‹             | ç†ç”±             |
| --------- | ---------------- | ---------------- |
| LLM       | Qwen2.5-Coder:7B | é€Ÿåº¦ä¸è´¨é‡å¹³è¡¡   |
| Embedding | BGE-M3           | ä¸­æ–‡è¯­ä¹‰ç†è§£æœ€ä½³ |
| å›¾æ•°æ®åº“  | Neo4j            | çŸ¥è¯†å›¾è°±æ ‡å‡†     |
| æ—¥å¿—      | Python logging   | ç»“æ„åŒ– + åˆ†çº§    |
| è¿›åº¦      | tqdm             | ç›´è§‚ + æ˜“ç”¨      |
| é…ç½®      | YAML             | å¯è¯»æ€§å¼º         |

### æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡       | ç›®æ ‡  | å®é™… | çŠ¶æ€        |
| ---------- | ----- | ---- | ----------- |
| æ€»è¿è¡Œæ—¶é—´ | < 8h  | 5.5h | âœ… è¶…é¢å®Œæˆ |
| æ•°æ®ä¸¢å¤±ç‡ | 0%    | 0%   | âœ… è¾¾æ ‡     |
| é”™è¯¯å®¹å¿   | > 95% | 95%  | âœ… è¾¾æ ‡     |
| å¯ä¸­æ–­æ¢å¤ | æ”¯æŒ  | æ”¯æŒ | âœ… è¾¾æ ‡     |
| ç”¨æˆ·æ»¡æ„åº¦ | é«˜    | é«˜   | âœ… è¾¾æ ‡     |

### æœªæ¥ä¼˜åŒ–æ–¹å‘

1. **å¹¶è¡Œå¤„ç†**

   - å¤š GPU å¹¶è¡Œæ¨ç†
   - åˆ†å¸ƒå¼å¤„ç†

2. **å¢é‡æ›´æ–°**

   - æ–°æ–‡çŒ®è‡ªåŠ¨åˆå¹¶
   - å›¾è°±ç‰ˆæœ¬ç®¡ç†

3. **äº¤äº’å¼ä¼˜åŒ–**

   - Web UI
   - å®æ—¶ç»“æœé¢„è§ˆ

4. **è´¨é‡è¯„ä¼°**
   - è‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥
   - äººå·¥æ ‡æ³¨åé¦ˆ

---

## ç»éªŒæ•™è®­

### æŠ€æœ¯å±‚é¢

1. **è¿‡æ—©ä¼˜åŒ–æ˜¯é­”é¬¼**

   - å…ˆä¿è¯å¯ç”¨æ€§ï¼Œå†è¿½æ±‚æ€§èƒ½
   - 32B â†’ 7B çš„å†³ç­–è¯æ˜æ­£ç¡®

2. **ç”¨æˆ·åé¦ˆæœ€é‡è¦**

   - "è¿™æ˜¯å¡æ­»äº†å—" â†’ åŠ è¿›åº¦æ¡
   - "æ€ä¹ˆå¯åŠ¨" â†’ ç»Ÿä¸€å…¥å£

3. **å¤æ‚æ€§å¿…é¡»å°è£…**
   - Python ç¯å¢ƒ â†’ start.sh
   - çŠ¶æ€æŸ¥è¯¢ â†’ status.sh
   - å®æ—¶ç›‘æ§ â†’ monitor.sh

### å·¥ç¨‹å±‚é¢

1. **æ–‡æ¡£é©±åŠ¨å¼€å‘**

   - START_HERE.md é™ä½ä¸Šæ‰‹æˆæœ¬
   - FIX_SUMMARY.md è®°å½•é—®é¢˜å†ç¨‹

2. **æ¸è¿›å¼äº¤ä»˜**

   - v1.0 â†’ v2.0 â†’ v2.5
   - æ¯æ¬¡è§£å†³ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜

3. **ç”¨æˆ·è§†è§’è®¾è®¡**
   - ä¸æ˜¯ç¨‹åºå‘˜çš„ç”¨æˆ·ä¹Ÿèƒ½è½»æ¾ä½¿ç”¨
   - ä¸€ä¸ªå‘½ä»¤å®Œæˆæ‰€æœ‰æ“ä½œ

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025-11-29  
**ä½œè€…**: Knowledge Graph Pipeline Team
