#!/usr/bin/env python3
"""
å¯¼å‡ºä¸‰å…ƒç»„ä¾¿äºäººå·¥å®¡æŸ¥
ç”Ÿæˆå¤šç§æ ¼å¼çš„å¯¼å‡ºæ–‡ä»¶ï¼ŒåŒ…å«è¯¦ç»†çš„ç»Ÿè®¡å’Œåˆ†æä¿¡æ¯
"""
import pandas as pd
import os
from datetime import datetime

print("="*80)
print("å¯¼å‡ºä¸‰å…ƒç»„ä¾¿äºäººå·¥å®¡æŸ¥")
print("="*80)

# è¯»å–åŸå§‹CSV
csv_path = 'output/triples_export.csv'
df = pd.read_csv(csv_path)

print(f"\nåŸå§‹æ•°æ®ç»Ÿè®¡:")
print(f"  æ€»è¡Œæ•°: {len(df)}")
print(f"  å…³ç³»ç±»å‹: {df['relationship'].nunique()}")
print(f"  å”¯ä¸€èŠ‚ç‚¹: {len(set(df['node_1'].unique()) | set(df['node_2'].unique()))}")

# ============================================================================
# 1. ç”ŸæˆæŒ‰å…³ç³»ç±»å‹åˆ†ç±»çš„å®¡æŸ¥è¡¨
# ============================================================================
print("\n" + "="*80)
print("1. ç”ŸæˆæŒ‰å…³ç³»ç±»å‹åˆ†ç±»çš„å®¡æŸ¥è¡¨")
print("="*80)

# æŒ‰å…³ç³»ç±»å‹åˆ†ç»„
rel_groups = df.groupby('relationship')

review_file = 'output/triples_by_relationship.csv'
with open(review_file, 'w', encoding='utf-8') as f:
    f.write("# çŸ¥è¯†å›¾è°±ä¸‰å…ƒç»„ - æŒ‰å…³ç³»ç±»å‹åˆ†ç±»\n")
    f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}\n")
    f.write(f"# æ€»è¡Œæ•°: {len(df)}\n")
    f.write(f"# å…³ç³»ç±»å‹: {df['relationship'].nunique()}\n\n")
    
    for rel_type in df['relationship'].unique():
        rel_df = df[df['relationship'] == rel_type].sort_values('weight', ascending=False)
        count = len(rel_df)
        avg_weight = rel_df['weight'].mean()
        
        f.write(f"\n{'='*80}\n")
        f.write(f"å…³ç³»ç±»å‹: {rel_type}\n")
        f.write(f"æ•°é‡: {count} æ¡\n")
        f.write(f"å¹³å‡æƒé‡: {avg_weight:.4f}\n")
        f.write(f"{'='*80}\n")
        f.write("node_1,relationship,node_2,weight\n")
        
        for _, row in rel_df.iterrows():
            f.write(f"{row['node_1']},{row['relationship']},{row['node_2']},{row['weight']}\n")

print(f"  âœ“ å·²ç”Ÿæˆ {review_file}")

# ============================================================================
# 2. ç”Ÿæˆå…³ç³»ç±»å‹ç»Ÿè®¡è¡¨
# ============================================================================
print("\n" + "="*80)
print("2. ç”Ÿæˆå…³ç³»ç±»å‹ç»Ÿè®¡è¡¨")
print("="*80)

rel_stats = df.groupby('relationship').agg({
    'weight': ['count', 'mean', 'min', 'max', 'std']
}).round(4)

rel_stats.columns = ['count', 'avg_weight', 'min_weight', 'max_weight', 'std_weight']
rel_stats = rel_stats.sort_values('count', ascending=False)

stats_file = 'output/relationship_statistics.csv'
rel_stats.to_csv(stats_file)
print(f"  âœ“ å·²ç”Ÿæˆ {stats_file}")

print("\n  å…³ç³»ç±»å‹ç»Ÿè®¡ï¼ˆå‰15ï¼‰:")
for rel, row in rel_stats.head(15).iterrows():
    print(f"    {rel:30s}: {int(row['count']):3d} æ¡, å¹³å‡æƒé‡: {row['avg_weight']:.4f}")

# ============================================================================
# 3. ç”ŸæˆèŠ‚ç‚¹ç»Ÿè®¡è¡¨
# ============================================================================
print("\n" + "="*80)
print("3. ç”ŸæˆèŠ‚ç‚¹ç»Ÿè®¡è¡¨")
print("="*80)

# ç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹çš„å‡ºåº¦å’Œå…¥åº¦
out_degree = df.groupby('node_1').size().rename('out_degree')
in_degree = df.groupby('node_2').size().rename('in_degree')

all_nodes = list(set(df['node_1'].unique()) | set(df['node_2'].unique()))
node_stats = pd.DataFrame(index=all_nodes)
node_stats['out_degree'] = out_degree
node_stats['in_degree'] = in_degree
node_stats = node_stats.fillna(0).astype(int)
node_stats['total_degree'] = node_stats['out_degree'] + node_stats['in_degree']
node_stats = node_stats.sort_values('total_degree', ascending=False)

nodes_file = 'output/node_statistics.csv'
node_stats.to_csv(nodes_file)
print(f"  âœ“ å·²ç”Ÿæˆ {nodes_file}")

print(f"\n  èŠ‚ç‚¹ç»Ÿè®¡:")
print(f"    æ€»èŠ‚ç‚¹æ•°: {len(node_stats)}")
print(f"    å¹³å‡åº¦æ•°: {node_stats['total_degree'].mean():.2f}")
print(f"    æœ€é«˜åº¦æ•°: {node_stats['total_degree'].max()}")

print("\n  åº¦æ•°æœ€é«˜çš„èŠ‚ç‚¹ï¼ˆå‰10ï¼‰:")
for node, row in node_stats.head(10).iterrows():
    print(f"    {node:40s}: å‡ºåº¦={int(row['out_degree']):2d}, å…¥åº¦={int(row['in_degree']):2d}, æ€»åº¦æ•°={int(row['total_degree']):2d}")

# ============================================================================
# 4. ç”Ÿæˆè´¨é‡æ£€æŸ¥æŠ¥å‘Š
# ============================================================================
print("\n" + "="*80)
print("4. ç”Ÿæˆè´¨é‡æ£€æŸ¥æŠ¥å‘Š")
print("="*80)

quality_file = 'output/quality_report.txt'
with open(quality_file, 'w', encoding='utf-8') as f:
    f.write("="*80 + "\n")
    f.write("çŸ¥è¯†å›¾è°±è´¨é‡æ£€æŸ¥æŠ¥å‘Š\n")
    f.write("="*80 + "\n\n")
    
    f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}\n\n")
    
    # åŸºæœ¬ç»Ÿè®¡
    f.write("ã€åŸºæœ¬ç»Ÿè®¡ã€‘\n")
    f.write(f"  æ€»ä¸‰å…ƒç»„æ•°: {len(df)}\n")
    f.write(f"  å”¯ä¸€èŠ‚ç‚¹æ•°: {len(node_stats)}\n")
    f.write(f"  å…³ç³»ç±»å‹æ•°: {df['relationship'].nunique()}\n\n")
    
    # å…³ç³»ç±»å‹åˆ†å¸ƒ
    f.write("ã€å…³ç³»ç±»å‹åˆ†å¸ƒã€‘\n")
    for rel, count in df['relationship'].value_counts().items():
        pct = count / len(df) * 100
        f.write(f"  {rel:30s}: {count:3d} ({pct:5.1f}%)\n")
    f.write("\n")
    
    # æƒé‡åˆ†å¸ƒ
    f.write("ã€æƒé‡åˆ†å¸ƒã€‘\n")
    f.write(f"  æœ€å°æƒé‡: {df['weight'].min():.6f}\n")
    f.write(f"  æœ€å¤§æƒé‡: {df['weight'].max():.6f}\n")
    f.write(f"  å¹³å‡æƒé‡: {df['weight'].mean():.6f}\n")
    f.write(f"  ä¸­ä½æƒé‡: {df['weight'].median():.6f}\n")
    f.write(f"  æ ‡å‡†å·®: {df['weight'].std():.6f}\n\n")
    
    # æ•°æ®è´¨é‡æ£€æŸ¥
    f.write("ã€æ•°æ®è´¨é‡æ£€æŸ¥ã€‘\n")
    
    # æ£€æŸ¥ä¸­æ–‡
    chinese_rels = df[df['relationship'].str.contains('[\u4e00-\u9fa5]', regex=True)]['relationship'].nunique()
    chinese_nodes_1 = df[df['node_1'].str.contains('[\u4e00-\u9fa5]', regex=True)].shape[0]
    chinese_nodes_2 = df[df['node_2'].str.contains('[\u4e00-\u9fa5]', regex=True)].shape[0]
    
    f.write(f"  ä¸­æ–‡å…³ç³»ç±»å‹: {chinese_rels} ä¸ª {'âœ…' if chinese_rels == 0 else 'âŒ'}\n")
    f.write(f"  ä¸­æ–‡èŠ‚ç‚¹: {chinese_nodes_1 + chinese_nodes_2} ä¸ª {'âœ…' if chinese_nodes_1 + chinese_nodes_2 == 0 else 'âŒ'}\n")
    
    # æ£€æŸ¥é‡å¤
    duplicates = df.duplicated(subset=['node_1', 'relationship', 'node_2']).sum()
    f.write(f"  é‡å¤ä¸‰å…ƒç»„: {duplicates} ä¸ª {'âœ…' if duplicates == 0 else 'âŒ'}\n")
    
    # æ£€æŸ¥å­¤ç«‹èŠ‚ç‚¹
    isolated = len([n for n in node_stats.index if node_stats.loc[n, 'total_degree'] == 0])
    f.write(f"  å­¤ç«‹èŠ‚ç‚¹: {isolated} ä¸ª {'âœ…' if isolated == 0 else 'âŒ'}\n")
    
    # æ£€æŸ¥è‡ªç¯
    self_loops = ((df['node_1'] == df['node_2']).sum())
    f.write(f"  è‡ªç¯å…³ç³»: {self_loops} ä¸ª {'âœ…' if self_loops == 0 else 'âŒ'}\n\n")
    
    # èŠ‚ç‚¹åº¦æ•°åˆ†æ
    f.write("ã€èŠ‚ç‚¹åº¦æ•°åˆ†æã€‘\n")
    f.write(f"  å¹³å‡å‡ºåº¦: {node_stats['out_degree'].mean():.2f}\n")
    f.write(f"  å¹³å‡å…¥åº¦: {node_stats['in_degree'].mean():.2f}\n")
    f.write(f"  æœ€é«˜å‡ºåº¦: {node_stats['out_degree'].max()}\n")
    f.write(f"  æœ€é«˜å…¥åº¦: {node_stats['in_degree'].max()}\n\n")
    
    # é«˜åº¦æ•°èŠ‚ç‚¹
    f.write("ã€åº¦æ•°æœ€é«˜çš„èŠ‚ç‚¹ï¼ˆå‰20ï¼‰ã€‘\n")
    for node, row in node_stats.head(20).iterrows():
        f.write(f"  {node:40s}: å‡ºåº¦={int(row['out_degree']):2d}, å…¥åº¦={int(row['in_degree']):2d}, æ€»åº¦æ•°={int(row['total_degree']):2d}\n")
    f.write("\n")
    
    # å…³ç³»ç±»å‹è¯¦ç»†ç»Ÿè®¡
    f.write("ã€å…³ç³»ç±»å‹è¯¦ç»†ç»Ÿè®¡ã€‘\n")
    for rel in df['relationship'].unique():
        rel_df = df[df['relationship'] == rel]
        f.write(f"  {rel}:\n")
        f.write(f"    æ•°é‡: {len(rel_df)}\n")
        f.write(f"    å¹³å‡æƒé‡: {rel_df['weight'].mean():.6f}\n")
        f.write(f"    æƒé‡èŒƒå›´: [{rel_df['weight'].min():.6f}, {rel_df['weight'].max():.6f}]\n")

print(f"  âœ“ å·²ç”Ÿæˆ {quality_file}")

# ============================================================================
# 5. ç”Ÿæˆå¯è§†åŒ–å‹å¥½çš„æ ¼å¼
# ============================================================================
print("\n" + "="*80)
print("5. ç”Ÿæˆå¯è§†åŒ–å‹å¥½çš„æ ¼å¼")
print("="*80)

# ç”ŸæˆæŒ‰æƒé‡æ’åºçš„å®¡æŸ¥è¡¨
sorted_file = 'output/triples_sorted_by_weight.csv'
df_sorted = df.sort_values('weight', ascending=False)
df_sorted.to_csv(sorted_file, index=False)
print(f"  âœ“ å·²ç”Ÿæˆ {sorted_file}")

# ç”Ÿæˆé«˜æƒé‡ä¸‰å…ƒç»„
high_weight_file = 'output/high_weight_triples.csv'
high_weight_df = df[df['weight'] >= 0.5].sort_values('weight', ascending=False)
high_weight_df.to_csv(high_weight_file, index=False)
print(f"  âœ“ å·²ç”Ÿæˆ {high_weight_file} ({len(high_weight_df)} æ¡)")

# ç”Ÿæˆä½æƒé‡ä¸‰å…ƒç»„
low_weight_file = 'output/low_weight_triples.csv'
low_weight_df = df[df['weight'] < 0.2].sort_values('weight', ascending=False)
low_weight_df.to_csv(low_weight_file, index=False)
print(f"  âœ“ å·²ç”Ÿæˆ {low_weight_file} ({len(low_weight_df)} æ¡)")

# ============================================================================
# 6. ç”Ÿæˆå®¡æŸ¥æ¸…å•
# ============================================================================
print("\n" + "="*80)
print("6. ç”Ÿæˆå®¡æŸ¥æ¸…å•")
print("="*80)

checklist_file = 'output/review_checklist.txt'
with open(checklist_file, 'w', encoding='utf-8') as f:
    f.write("="*80 + "\n")
    f.write("çŸ¥è¯†å›¾è°±äººå·¥å®¡æŸ¥æ¸…å•\n")
    f.write("="*80 + "\n\n")
    
    f.write("ã€å®¡æŸ¥æŒ‡å—ã€‘\n\n")
    
    f.write("1. å…³ç³»ç±»å‹å®¡æŸ¥\n")
    f.write("   - æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å…³ç³»ç±»å‹éƒ½æ˜¯è‹±æ–‡\n")
    f.write("   - æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ‹¼å†™é”™è¯¯æˆ–ä¸ä¸€è‡´\n")
    f.write("   - æ£€æŸ¥æ˜¯å¦å­˜åœ¨åŒä¹‰å…³ç³»æœªåˆå¹¶\n")
    f.write("   æ–‡ä»¶: relationship_statistics.csv\n\n")
    
    f.write("2. èŠ‚ç‚¹å®¡æŸ¥\n")
    f.write("   - æ£€æŸ¥æ˜¯å¦æ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯è‹±æ–‡\n")
    f.write("   - æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ‹¼å†™é”™è¯¯æˆ–ä¸ä¸€è‡´\n")
    f.write("   - æ£€æŸ¥åº¦æ•°å¼‚å¸¸çš„èŠ‚ç‚¹\n")
    f.write("   æ–‡ä»¶: node_statistics.csv\n\n")
    
    f.write("3. ä¸‰å…ƒç»„é€»è¾‘å®¡æŸ¥\n")
    f.write("   - æ£€æŸ¥æ˜¯å¦å­˜åœ¨é€»è¾‘é”™è¯¯ï¼ˆå¦‚ç–¾ç—…å¯„ç”Ÿäºç—…åŸä½“ï¼‰\n")
    f.write("   - æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸åˆç†çš„å…³ç³»\n")
    f.write("   - æ£€æŸ¥æƒé‡æ˜¯å¦åˆç†\n")
    f.write("   æ–‡ä»¶: triples_by_relationship.csv\n\n")
    
    f.write("4. æƒé‡å®¡æŸ¥\n")
    f.write("   - æ£€æŸ¥é«˜æƒé‡ä¸‰å…ƒç»„æ˜¯å¦åˆç†\n")
    f.write("   - æ£€æŸ¥ä½æƒé‡ä¸‰å…ƒç»„æ˜¯å¦åº”è¯¥åˆ é™¤\n")
    f.write("   æ–‡ä»¶: high_weight_triples.csv, low_weight_triples.csv\n\n")
    
    f.write("ã€æ•°æ®è´¨é‡æŒ‡æ ‡ã€‘\n\n")
    f.write(f"âœ“ æ€»ä¸‰å…ƒç»„æ•°: {len(df)}\n")
    f.write(f"âœ“ å”¯ä¸€èŠ‚ç‚¹æ•°: {len(node_stats)}\n")
    f.write(f"âœ“ å…³ç³»ç±»å‹æ•°: {df['relationship'].nunique()}\n")
    f.write(f"âœ“ ä¸­æ–‡å…³ç³»: {chinese_rels} ä¸ª\n")
    f.write(f"âœ“ ä¸­æ–‡èŠ‚ç‚¹: {chinese_nodes_1 + chinese_nodes_2} ä¸ª\n")
    f.write(f"âœ“ é‡å¤ä¸‰å…ƒç»„: {duplicates} ä¸ª\n")
    f.write(f"âœ“ å­¤ç«‹èŠ‚ç‚¹: {isolated} ä¸ª\n")
    f.write(f"âœ“ è‡ªç¯å…³ç³»: {self_loops} ä¸ª\n\n")
    
    f.write("ã€å»ºè®®çš„å®¡æŸ¥é¡ºåºã€‘\n\n")
    f.write("1. é¦–å…ˆæŸ¥çœ‹ quality_report.txt äº†è§£æ•´ä½“æ•°æ®è´¨é‡\n")
    f.write("2. æŸ¥çœ‹ relationship_statistics.csv å®¡æŸ¥å…³ç³»ç±»å‹\n")
    f.write("3. æŸ¥çœ‹ node_statistics.csv å®¡æŸ¥èŠ‚ç‚¹\n")
    f.write("4. æŸ¥çœ‹ triples_by_relationship.csv æŒ‰å…³ç³»ç±»å‹å®¡æŸ¥ä¸‰å…ƒç»„\n")
    f.write("5. æŸ¥çœ‹ high_weight_triples.csv å®¡æŸ¥é«˜æƒé‡ä¸‰å…ƒç»„\n")
    f.write("6. æŸ¥çœ‹ low_weight_triples.csv å†³å®šæ˜¯å¦åˆ é™¤ä½æƒé‡ä¸‰å…ƒç»„\n")

print(f"  âœ“ å·²ç”Ÿæˆ {checklist_file}")

# ============================================================================
# æ€»ç»“
# ============================================================================
print("\n" + "="*80)
print("âœ“ å¯¼å‡ºå®Œæˆï¼")
print("="*80)

print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
print(f"  1. triples_export.csv - åŸå§‹ä¸‰å…ƒç»„ï¼ˆæ ‡å‡†æ ¼å¼ï¼‰")
print(f"  2. triples_by_relationship.csv - æŒ‰å…³ç³»ç±»å‹åˆ†ç±»çš„ä¸‰å…ƒç»„")
print(f"  3. relationship_statistics.csv - å…³ç³»ç±»å‹ç»Ÿè®¡")
print(f"  4. node_statistics.csv - èŠ‚ç‚¹ç»Ÿè®¡")
print(f"  5. quality_report.txt - è´¨é‡æ£€æŸ¥æŠ¥å‘Š")
print(f"  6. triples_sorted_by_weight.csv - æŒ‰æƒé‡æ’åºçš„ä¸‰å…ƒç»„")
print(f"  7. high_weight_triples.csv - é«˜æƒé‡ä¸‰å…ƒç»„ï¼ˆæƒé‡â‰¥0.5ï¼‰")
print(f"  8. low_weight_triples.csv - ä½æƒé‡ä¸‰å…ƒç»„ï¼ˆæƒé‡<0.2ï¼‰")
print(f"  9. review_checklist.txt - äººå·¥å®¡æŸ¥æ¸…å•")

print("\nğŸ“Œ å»ºè®®çš„å®¡æŸ¥æµç¨‹:")
print("  1. é˜…è¯» review_checklist.txt äº†è§£å®¡æŸ¥æŒ‡å—")
print("  2. æŸ¥çœ‹ quality_report.txt äº†è§£æ•´ä½“è´¨é‡")
print("  3. æŒ‰ç…§æ¸…å•ä¸­çš„å»ºè®®é€ä¸ªå®¡æŸ¥å„ä¸ªæ–‡ä»¶")
print("  4. æ ¹æ®å®¡æŸ¥ç»“æœè¿›è¡Œå¿…è¦çš„ä¿®æ­£")

print("\næ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ° output/ ç›®å½•")
