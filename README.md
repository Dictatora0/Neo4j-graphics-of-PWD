# æ¾æçº¿è™«ç—…çŸ¥è¯†å›¾è°±æ„å»ºç³»ç»Ÿ

<div align="center">

**çŸ¥è¯†å·¥ç¨‹ç¬¬äºŒç»„ - åŸºäºæ–‡çŒ®çš„æ¾æçº¿è™«ç—…çŸ¥è¯†å›¾è°±é¡¹ç›®**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org)
[![Neo4j](https://img.shields.io/badge/Neo4j-4.x%20%7C%205.x-green.svg)](https://neo4j.com)

**GitHub ä»“åº“**ï¼š[https://github.com/Dictatora0/Neo4j-graphics-of-PWD.git](https://github.com/Dictatora0/Neo4j-graphics-of-PWD.git)

</div>

---

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®ä»æ¾æçº¿è™«ç—…ï¼ˆPine Wilt Diseaseï¼ŒPWDï¼‰ç›¸å…³ PDF æ–‡çŒ®ä¸­è‡ªåŠ¨æŠ½å–å®ä½“å’Œå…³ç³»ï¼Œæ„å»ºå¯åœ¨ Neo4j ä¸­æŸ¥è¯¢å’Œå¯è§†åŒ–çš„é¢†åŸŸçŸ¥è¯†å›¾è°±ã€‚

ç®¡é“æ ¸å¿ƒç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼š

- ä» PDF ä¸­æŠ½å–æ–‡æœ¬ï¼Œå¹¶åšåŸºç¡€æ¸…æ´—
- ä½¿ç”¨æœ¬åœ°å¤§æ¨¡å‹ï¼ˆé€šè¿‡ Ollamaï¼‰è¿›è¡Œæ¦‚å¿µä¸å…³ç³»æŠ½å–ã€åµŒå…¥å¼å»é‡å’Œé‚»è¿‘æ€§åˆ†æ
- ç»“åˆè§„åˆ™å’Œç»Ÿè®¡ï¼Œå¯¹å…³ç³»è¿›è¡Œè¿‡æ»¤ã€è¯­ä¹‰ä½“æ£€å’Œä¿®æ­£åå¯¼å…¥ Neo4j

ç›®æ ‡æ˜¯å¾—åˆ°ä¸€ä»½ç»“æ„æ¸…æ™°ã€æ•°æ®è´¨é‡å¯æ§çš„æ¾æçº¿è™«ç—…çŸ¥è¯†å›¾è°±ï¼Œæ”¯æŒè¿›ä¸€æ­¥åˆ†æå’Œå±•ç¤ºã€‚

---

## å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- Neo4j 4.x æˆ– 5.x
- æœ¬åœ° LLM æœåŠ¡ï¼ˆé»˜è®¤é€šè¿‡ Ollama è°ƒç”¨ `llama3.2:3b`ï¼‰

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
python -m spacy download zh_core_web_sm
python -m spacy download en_core_web_sm
```

### å‡†å¤‡æ•°æ®

1. å°†å¾…å¤„ç†çš„ PDF æ–‡çŒ®æ”¾å…¥é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ `æ–‡çŒ®/` ç›®å½•
2. æ ¹æ®éœ€è¦è°ƒæ•´ `config/config.yaml` ä¸­çš„å‚æ•°ï¼ˆè§ä¸‹æ–‡â€œé…ç½®è¯´æ˜â€ï¼‰

### è¿è¡Œæ„å»ºç®¡é“

```bash
# æ–¹å¼ä¸€ï¼šç›´æ¥è¿è¡Œä¸»ç¨‹åº
python main.py

# æˆ–ä½¿ç”¨å°è£…å¥½çš„è„šæœ¬
./scripts/workflow/run_complete_workflow.sh
```

ä¸»ç¨‹åºå®Œæˆåï¼Œä¼šåœ¨ `output/` ç›®å½•ç”Ÿæˆï¼š

- `concepts.csv` / `relationships.csv`ï¼šLLM æŠ½å–å’Œå»é‡åçš„æ¦‚å¿µä¸å…³ç³»
- `entities_clean.csv` / `relations_clean.csv`ï¼šæ¸…æ´—åçš„å®ä½“å’Œå…³ç³»
- `neo4j_import/`ï¼šå¯¼å…¥ Neo4j æ‰€éœ€çš„ CSV ä¸ Cypher è„šæœ¬
- `statistics_report.txt`ï¼šæŠ½å–ä¸æ¸…æ´—é˜¶æ®µçš„ç»Ÿè®¡ç»“æœ

### å¯¼å…¥ Neo4j

å¯¼å…¥æ¨èä½¿ç”¨ä¸¤ç§æ–¹å¼ä¹‹ä¸€ï¼š

1. **ä½¿ç”¨ä¸‰å…ƒç»„å¯¼å…¥è„šæœ¬ï¼ˆæœ€ç»ˆå›¾è°±ï¼‰**

   ```bash
   python import_to_neo4j_final.py
   ```

   è¯¥è„šæœ¬ä¼šï¼š

   - è¯»å– `output/triples_export_semantic_clean.csv`ï¼ˆè‹¥å­˜åœ¨ï¼Œå¦åˆ™ä½¿ç”¨ `triples_export.csv`ï¼‰
   - æ¸…ç©ºå½“å‰æ•°æ®åº“
   - åˆ›å»ºèŠ‚ç‚¹ä¸å…³ç³»ï¼Œå¹¶æ·»åŠ ç±»å‹ã€æƒé‡ã€æ ·å¼ç­‰å±æ€§
   - ç”Ÿæˆç´¢å¼•å’ŒåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯

2. **ä½¿ç”¨ CSV + Cypher å¯¼å…¥è„šæœ¬**

   ```bash
   cd output/neo4j_import
   python import_to_neo4j.py
   # æˆ–åœ¨ Neo4j Browser ä¸­æ‰§è¡Œ import.cypher
   ```

   ä½¿ç”¨ `nodes.csv` / `relations.csv` æ„å»ºä¸€ä¸ªæ›´ç®€åŒ–çš„å®ä½“-å…³ç³»å›¾ã€‚

å¯¼å…¥å®Œæˆåï¼Œå¯åœ¨æµè§ˆå™¨è®¿é—® Neo4jï¼š

- åœ°å€ï¼š`http://localhost:7474`
- ç”¨æˆ·åï¼š`neo4j`
- å¯†ç ï¼š`12345678`ï¼ˆé»˜è®¤å€¼ï¼Œè§ `config/config.yaml`ï¼‰

---

## å·¥ä½œæµç¨‹ä¸æŠ€æœ¯å®ç°è¯¦è§£

æ•´ä¸ªæµç¨‹å¯ä»¥åˆ†ä¸ºå››ä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µéƒ½æœ‰è¯¦ç»†çš„æŠ€æœ¯å®ç°ç»†èŠ‚ï¼š

---

### é˜¶æ®µ 1ï¼šPDF æ–‡æœ¬æå–ä¸é¢„å¤„ç†

**æ ¸å¿ƒæ¨¡å—**ï¼š`pdf_extractor.py`ã€`ocr_processor.py`ã€`parallel_processor.py`

#### 1.1 æŠ€æœ¯æ ˆ

- **PyMuPDF (fitz)**ï¼šä¸»è¦ PDF è§£æåº“

  - é€Ÿåº¦å¿«ï¼ˆ1-2 é¡µ/ç§’ï¼‰
  - æ”¯æŒå¤æ‚æ ¼å¼
  - æå–æ–‡æœ¬åŒæ—¶ä¿ç•™å¸ƒå±€ä¿¡æ¯

- **OCR æ”¯æŒï¼ˆå¯é€‰ï¼‰**ï¼š

  - Tesseract OCRï¼šå¼€æº OCR å¼•æ“
  - PaddleOCRï¼šä¸­æ–‡è¯†åˆ«æ•ˆæœæ›´å¥½
  - è‡ªåŠ¨æ£€æµ‹æ–‡æœ¬è´¨é‡ï¼Œä½äºé˜ˆå€¼æ—¶è§¦å‘ OCR

- **å¹¶è¡Œå¤„ç†**ï¼š
  - ä½¿ç”¨ `multiprocessing` å¹¶è¡Œå¤„ç†å¤šä¸ª PDF
  - é»˜è®¤ 8 ä¸ªå·¥ä½œè¿›ç¨‹
  - åŸºäºé˜Ÿåˆ—çš„ä»»åŠ¡åˆ†é…

#### 1.2 å…³é”®ç®—æ³•

**æ–‡æœ¬æ¸…æ´—æµç¨‹**ï¼š

```python
1. ç§»é™¤æ§åˆ¶å­—ç¬¦: [\x00-\x08\x0b-\x0c\x0e-\x1f]
2. ç»Ÿä¸€è¡Œç»“æŸç¬¦: \r\n â†’ \n
3. å»é™¤é¡µçœ‰é¡µè„šæ¨¡å¼:
   - "ç¬¬Xé¡µ" / "Page X"
   - "ç‰ˆæƒæ‰€æœ‰" / "Copyright"
   - é¡µç æ¨¡å¼: "X/Y"
4. è¿‡æ»¤å…ƒæ•°æ®å…³é”®è¯:
   - ä½œè€…ã€å•ä½ã€æ”¶ç¨¿ã€åŸºé‡‘é¡¹ç›®
5. æ£€æµ‹å¹¶æˆªæ–­å‚è€ƒæ–‡çŒ®éƒ¨åˆ†
```

**å‚è€ƒæ–‡çŒ®æ£€æµ‹**ï¼š

```python
# å…³é”®è¯åŒ¹é…
keywords = ['å‚è€ƒæ–‡çŒ®', 'References', 'Bibliography']

# å¯å‘å¼è§„åˆ™
- æ£€æµ‹è¿ç»­å¼•ç”¨æ ¼å¼: "[1] ä½œè€…..."
- è¯†åˆ«å¼•ç”¨å¯†åº¦çªå¢æ®µè½
- åŸºäºç¼©è¿›å’Œç¼–å·æ¨¡å¼
```

**ç¼“å­˜æœºåˆ¶**ï¼š

- ä½¿ç”¨ `hashlib.md5` å¯¹æ–‡ä»¶å†…å®¹ç”ŸæˆæŒ‡çº¹
- ç¼“å­˜ç»“æ„ï¼š`{pdf_hash: extracted_text}`
- æ”¯æŒå¢é‡å¤„ç†ï¼Œé¿å…é‡å¤æå–

#### 1.3 æ€§èƒ½ä¼˜åŒ–

| ä¼˜åŒ–æŠ€æœ¯     | æå‡æ•ˆæœ     | è¯´æ˜                |
| ------------ | ------------ | ------------------- |
| å¹¶è¡Œå¤„ç†     | 5-8 å€       | å¤šæ ¸ CPU åˆ©ç”¨ç‡æå‡ |
| ç¼“å­˜æœºåˆ¶     | 100 å€       | é¿å…é‡å¤æå–        |
| OCR æŒ‰éœ€è§¦å‘ | èŠ‚çœ 90%æ—¶é—´ | ä»…å¯¹ä½è´¨é‡æ–‡æœ¬å¯ç”¨  |
| æ–‡æœ¬åˆ†å—     | å‡å°‘å†…å­˜ 50% | æµå¼å¤„ç†å¤§æ–‡ä»¶      |

#### 1.4 å¯æ”¹è¿›ç‚¹

- ğŸ”„ **è¡¨æ ¼æå–**ï¼šä½¿ç”¨ `camelot` æˆ– `pdfplumber` ç»“æ„åŒ–æå–è¡¨æ ¼
- ğŸ”„ **å›¾ç‰‡ OCR**ï¼šæå–å›¾ç‰‡ä¸­çš„æ–‡å­—ä¿¡æ¯
- ğŸ”„ **å¤šè¯­è¨€æ”¯æŒ**ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶åˆ†ç¦»ä¸­è‹±æ–‡
- ğŸ”„ **PDF ç»“æ„è§£æ**ï¼šè¯†åˆ«ç« èŠ‚ã€æ ‡é¢˜ã€æ‘˜è¦ç­‰è¯­ä¹‰ç»“æ„
- ğŸ”„ **å…¬å¼è¯†åˆ«**ï¼šä½¿ç”¨ LaTeX-OCR æå–æ•°å­¦å…¬å¼

---

### é˜¶æ®µ 2ï¼šLLM æ¦‚å¿µä¸å…³ç³»æŠ½å–

**æ ¸å¿ƒæ¨¡å—**ï¼š`enhanced_pipeline.py`ã€`concept_extractor.py`ã€`concept_deduplicator.py`

#### 2.1 æŠ€æœ¯æ¶æ„

**LLM æä¾›å•†**ï¼š

- **Ollama æœ¬åœ°æœåŠ¡**ï¼š
  - æ¨¡å‹ï¼š`llama3.2:3b` (é»˜è®¤)
  - API ç«¯ç‚¹ï¼š`http://localhost:11434/api/generate`
  - è¶…æ—¶è®¾ç½®ï¼š120 ç§’
  - é‡è¯•æœºåˆ¶ï¼š3 æ¬¡

**Prompt Engineering**ï¼š

```python
# ç³»ç»Ÿæç¤ºè¯ï¼ˆé¢†åŸŸä¸“å®¶è§’è‰²ï¼‰
system_prompt = """
ä½ æ˜¯æ¾æçº¿è™«ç—…çŸ¥è¯†å›¾è°±æ„å»ºä¸“å®¶ã€‚

é‡ç‚¹å…³æ³¨:
- ç—…åŸä½“: æ¾æçº¿è™«ã€ä¼´ç”Ÿç»†èŒ
- å¯„ä¸»æ¤ç‰©: æ¾æ ‘ã€é©¬å°¾æ¾ã€é»‘æ¾
- åª’ä»‹æ˜†è™«: æ¾è¤å¤©ç‰›
- ç—…å®³ç—‡çŠ¶: èè”«ã€æ¯æ­»ã€å˜è‰²
- é˜²æ²»æªæ–½: è¯å‰‚ã€è¯±æ•å™¨
- ç¯å¢ƒå› å­: æ¸©åº¦ã€æ¹¿åº¦ã€æµ·æ‹”

ç±»åˆ«: pathogen, host, vector, symptom,
      treatment, environment, location

é¿å…: é€šç”¨è¯(å› ç´ ã€è¿‡ç¨‹ã€æ–¹æ³•)
"""

# è¾“å‡ºæ ¼å¼ï¼ˆç»“æ„åŒ– JSONï¼‰
output_format = [
  {
    "entity": "æ¦‚å¿µå",
    "importance": 1-5,  # é‡è¦æ€§è¯„åˆ†
    "category": "ç±»åˆ«"
  }
]
```

**å…³ç³»æŠ½å– Prompt**ï¼š

```python
system_prompt = """
æå–æ¦‚å¿µé—´çš„è¯­ä¹‰å…³ç³»ã€‚

å…³ç³»ç±»å‹:
- INFECTS(æ„ŸæŸ“): ç—…åŸâ†’å¯„ä¸»
- TRANSMITS(ä¼ æ’­): åª’ä»‹â†’ç—…åŸ/ç–¾ç—…
- PARASITIZES(å¯„ç”Ÿ): åª’ä»‹/ç—…åŸâ†’å¯„ä¸»
- CAUSES(å¼•èµ·): ç—…åŸâ†’ç—‡çŠ¶
- TREATS(é˜²æ²»): æªæ–½â†’ç—…åŸ/ç–¾ç—…
- DISTRIBUTED_IN(åˆ†å¸ƒ): ç”Ÿç‰©â†’åœ°åŒº
- AFFECTS(å½±å“): å› ç´ â†’ç–¾ç—…/å¯„ä¸»

è¾“å‡º: [{"head": "A", "tail": "B",
        "relation": "ç±»å‹", "confidence": 0-1}]
"""
```

#### 2.2 å…³é”®å‚æ•°è°ƒä¼˜

```yaml
LLM å‚æ•°:
  temperature: 0.1 # ä½æ¸©åº¦ä¿è¯è¾“å‡ºç¨³å®š
  top_p: 0.9 # æ ¸é‡‡æ ·
  top_k: 40 # å€™é€‰è¯é™åˆ¶
  max_tokens: 800 # é™åˆ¶è¾“å‡ºé•¿åº¦

æ–‡æœ¬åˆ†å—:
  chunk_size: 2000 # å­—ç¬¦æ•°ï¼ˆé€‚é… token é™åˆ¶ï¼‰
  overlap: 200 # é‡å é¿å…è¯­ä¹‰æ–­è£‚
  max_chunks: 100 # æ€»å—æ•°é™åˆ¶ï¼ˆæ§åˆ¶æˆæœ¬ï¼‰

è¾“å‡ºè§£æ:
  json_repair: True # è‡ªåŠ¨ä¿®å¤æ ¼å¼é”™è¯¯
  retry_on_error: 3 # è§£æå¤±è´¥é‡è¯•
```

#### 2.3 æ¦‚å¿µå»é‡ç®—æ³•

**åµŒå…¥æ¨¡å‹é€‰æ‹©**ï¼š

```python
# ä¸»é€‰ï¼šsentence-transformers
model = "sentence-transformers/paraphrase-MiniLM-L6-v2"
- æ”¯æŒå¤šè¯­è¨€
- 384 ç»´å‘é‡
- é€Ÿåº¦å¿«ï¼ˆ50 æ¦‚å¿µ/ç§’ï¼‰

# å¤‡é€‰ï¼šTF-IDF (æ— éœ€é¢„è®­ç»ƒ)
- åŸºäºå­—ç¬¦ n-gram (2-3)
- 100 ç»´å‘é‡
- é€‚åˆå°è§„æ¨¡æ•°æ®
```

**å»é‡ç­–ç•¥**ï¼š

```python
# 1. è®¡ç®—è¯­ä¹‰åµŒå…¥
embeddings = model.encode(concepts)  # [N, 384]

# 2. ç›¸ä¼¼åº¦çŸ©é˜µ
similarity = cosine_similarity(embeddings)  # [N, N]

# 3. è´ªå¿ƒèšç±»
threshold = 0.85  # ç›¸ä¼¼åº¦é˜ˆå€¼
for i, concept_i in enumerate(concepts):
    if used[i]: continue
    canonical = concept_i  # é¦–ä¸ªä½œä¸ºè§„èŒƒå½¢å¼

    for j in range(i+1, len(concepts)):
        if similarity[i][j] >= threshold:
            mapping[concept_j] = canonical  # æ˜ å°„åˆ°è§„èŒƒå½¢å¼
            used[j] = True

# 4. å±æ€§åˆå¹¶
importance = max(group_importances)    # å–æœ€é«˜
category = most_common(group_categories) # å–ä¼—æ•°
connections = sum(group_connections)   # ç´¯åŠ è¿æ¥æ•°
```

**é˜ˆå€¼è°ƒä¼˜ç­–ç•¥**ï¼š

```
ç›¸ä¼¼åº¦é˜ˆå€¼ similarity_threshold:
- 0.80-0.83: æ¿€è¿›å»é‡ï¼Œé€‚åˆåˆæ­¥æ¸…æ´—
- 0.83-0.87: å¹³è¡¡æ¨¡å¼ï¼ˆæ¨èï¼‰
- 0.87-0.95: ä¿å®ˆæ¨¡å¼ï¼Œä¿ç•™ç»†å¾®å·®å¼‚
```

#### 2.4 æ€§èƒ½åˆ†æ

| æ­¥éª¤     | æ—¶é—´å¼€é”€   | ç“¶é¢ˆ     |
| -------- | ---------- | -------- |
| PDF æå– | 1-2 åˆ†é’Ÿ   | I/O      |
| æ–‡æœ¬åˆ†å— | <10 ç§’     | è®¡ç®—     |
| LLM æ¨ç† | 10-30 åˆ†é’Ÿ | ä¸»è¦ç“¶é¢ˆ |
| æ¦‚å¿µå»é‡ | 10-30 ç§’   | åµŒå…¥è®¡ç®— |
| å…³ç³»åˆå¹¶ | <5 ç§’      | å†…å­˜     |

**LLM è°ƒç”¨ç»Ÿè®¡**ï¼ˆ30 ä¸ªæ–‡æœ¬å—ä¸ºä¾‹ï¼‰ï¼š

```
è°ƒç”¨æ¬¡æ•°: 60 æ¬¡ï¼ˆæ¦‚å¿µ + å…³ç³»å„ 30ï¼‰
å¹³å‡å»¶è¿Ÿ: 3-8 ç§’/æ¬¡
æ€»æ—¶é•¿: 5-15 åˆ†é’Ÿ
Token æ¶ˆè€—: ~60K input + ~24K output
```

#### 2.5 å¯æ”¹è¿›ç‚¹

- ğŸ”„ **Few-shot Learning**ï¼šåœ¨ prompt ä¸­æ·»åŠ ç¤ºä¾‹æå‡å‡†ç¡®ç‡
- ğŸ”„ **Function Calling**ï¼šä½¿ç”¨ GPT-4 çš„ç»“æ„åŒ–è¾“å‡ºæ¨¡å¼
- ğŸ”„ **æ‰¹å¤„ç†ä¼˜åŒ–**ï¼šåˆå¹¶å¤šä¸ªå°å—å‡å°‘ API è°ƒç”¨
- ğŸ”„ **æœ¬åœ° LLM ä¼˜åŒ–**ï¼šä½¿ç”¨é‡åŒ–æ¨¡å‹ï¼ˆ4-bitï¼‰åŠ é€Ÿæ¨ç†
- ğŸ”„ **æ··åˆç­–ç•¥**ï¼šè§„åˆ™ + LLM äº’è¡¥æå‡å¬å›ç‡
- ğŸ”„ **ä¸»åŠ¨å­¦ä¹ **ï¼šå¯¹ä½ç½®ä¿¡åº¦æ ·æœ¬äººå·¥æ ‡æ³¨è¿­ä»£æ”¹è¿›
- ğŸ”„ **å±‚æ¬¡èšç±»**ï¼šHDBSCAN æ›¿ä»£ç®€å•é˜ˆå€¼èšç±»

---

### é˜¶æ®µ 3ï¼šæ•°æ®æ¸…æ´—ä¸è´¨é‡æ§åˆ¶

**æ ¸å¿ƒæ¨¡å—**ï¼š`data_cleaner.py`ã€`neo4j_generator.py`ã€`entity_linker.py`

#### 3.1 æ¸…æ´—è§„åˆ™ä½“ç³»

**å®ä½“è¿‡æ»¤è§„åˆ™**ï¼š

```python
# 1. å­—ç¬¦é•¿åº¦è¿‡æ»¤
min_length = 2          # è¿‡çŸ­å®ä½“ï¼ˆå¦‚"çš„"ã€"å’Œ"ï¼‰
max_length = 50         # è¿‡é•¿å®ä½“ï¼ˆå¯èƒ½æ˜¯å¥å­ç‰‡æ®µï¼‰

# 2. åœç”¨è¯è¿‡æ»¤
stopwords = load('config/stopwords.txt')
# åŒ…å«: å› ç´ ã€è¿‡ç¨‹ã€æ–¹æ³•ã€å½±å“ã€ä½œç”¨ ç­‰é€šç”¨è¯

# 3. ç‰¹æ®Šå­—ç¬¦è¿‡æ»¤
invalid_patterns = [
    r'^[0-9]+$',        # çº¯æ•°å­—
    r'^[a-zA-Z]{1,2}$', # å•ä¸ªå­—æ¯
    r'[^\w\s\-()]',     # ç‰¹æ®Šç¬¦å·
]

# 4. é¢‘æ¬¡è¿‡æ»¤
min_frequency = 2       # è‡³å°‘å‡ºç° 2 æ¬¡
```

**å…³ç³»è¿‡æ»¤è§„åˆ™**ï¼š

```python
# 1. ç½®ä¿¡åº¦é˜ˆå€¼
confidence_threshold = 0.65

# 2. è‡ªç¯æ£€æµ‹
head == tail â†’ åˆ é™¤

# 3. é‡å¤å…³ç³»åˆå¹¶
(A, R, B) + (A, R, B) â†’ æƒé‡ç´¯åŠ 

# 4. å¯¹ç§°å…³ç³»å¤„ç†
(A, CO_OCCURS_WITH, B) â‰ˆ (B, CO_OCCURS_WITH, A)
â†’ ä»…ä¿ç•™ä¸€æ¡ï¼Œæƒé‡ç´¯åŠ 
```

**å®ä½“å‘½åè§„èŒƒåŒ–**ï¼š

```python
# 1. å¤§å°å†™ç»Ÿä¸€
- ä¸­æ–‡æ¦‚å¿µ: ä¿æŒåŸæ ·
- è‹±æ–‡æ¦‚å¿µ: å°å†™åŒ–
- ä¸“æœ‰åè¯: é¦–å­—æ¯å¤§å†™

# 2. ç©ºæ ¼æ ‡å‡†åŒ–
å¤šä¸ªç©ºæ ¼ â†’ å•ä¸ªç©ºæ ¼
å‰åç©ºæ ¼ â†’ å»é™¤

# 3. åŒä¹‰è¯åˆå¹¶
mapping = {
    "æ¾æçº¿è™«": "bursaphelenchus xylophilus",
    "å¤©ç‰›": "monochamus alternatus",
    "é»‘æ¾": "pinus thunbergii"
}

# 4. ç¼©å†™æ‰©å±•
"PWD" â†’ "pine wilt disease"
```

#### 3.2 å®ä½“é“¾æ¥

**å®ä½“é“¾æ¥ç­–ç•¥**ï¼š

```python
# 1. ç²¾ç¡®åŒ¹é…
if entity in knowledge_base:
    return kb_entity

# 2. æ¨¡ç³ŠåŒ¹é…ï¼ˆç¼–è¾‘è·ç¦»ï¼‰
def levenshtein_distance(s1, s2):
    # å…è®¸ 20% ç¼–è¾‘è·ç¦»
    threshold = 0.8

# 3. è¯å¹²æå–
from nltk.stem import PorterStemmer
stem(entity) == stem(kb_entity)

# 4. å‘é‡ç›¸ä¼¼åº¦
embedding_similarity(entity, kb_entity) > 0.90
```

**çŸ¥è¯†åº“æ¥æº**ï¼š

```python
# é¢†åŸŸè¯å…¸ï¼ˆdomain_dict.jsonï¼‰
{
  "ç—…åŸä½“": [
    "bursaphelenchus xylophilus",
    "æ¾æçº¿è™«"
  ],
  "å¯„ä¸»": [
    "pinus thunbergii", "é»‘æ¾",
    "pinus massoniana", "é©¬å°¾æ¾"
  ]
}

# å¤–éƒ¨çŸ¥è¯†åº“ï¼ˆå¯æ‰©å±•ï¼‰
- WikiData
- UMLS (åŒ»å­¦ç»Ÿä¸€è¯­è¨€ç³»ç»Ÿ)
- ç”Ÿç‰©åˆ†ç±»æ•°æ®åº“
```

#### 3.3 Neo4j å¯¼å…¥æ–‡ä»¶ç”Ÿæˆ

**CSV æ ¼å¼è§„èŒƒ**ï¼š

```python
# nodes.csv
id,name,type,importance,connections
concept_001,bursaphelenchus xylophilus,Pathogen,5,23
concept_002,pinus thunbergii,Host,4,18

# relations.csv
source,target,relation,weight,confidence,source_pdf
concept_001,concept_002,INFECTS,0.92,0.88,paper1.pdf
```

**Cypher è„šæœ¬ç”Ÿæˆ**ï¼š

```cypher
// 1. åˆ›å»ºå”¯ä¸€æ€§çº¦æŸ
CREATE CONSTRAINT concept_name_unique
FOR (n:Concept) REQUIRE n.name IS UNIQUE;

// 2. æ‰¹é‡å¯¼å…¥èŠ‚ç‚¹ï¼ˆMERGE é¿å…é‡å¤ï¼‰
LOAD CSV WITH HEADERS FROM 'file:///nodes.csv' AS row
MERGE (n:Concept {name: row.name})
SET n.type = row.type,
    n.importance = toInteger(row.importance);

// 3. åˆ›å»ºç´¢å¼•
CREATE INDEX concept_type_index
FOR (n:Concept) ON (n.type);

// 4. æ‰¹é‡å¯¼å…¥å…³ç³»
LOAD CSV WITH HEADERS FROM 'file:///relations.csv' AS row
MATCH (a:Concept {name: row.source})
MATCH (b:Concept {name: row.target})
MERGE (a)-[r:${row.relation}]->(b)
SET r.weight = toFloat(row.weight);
```

#### 3.4 è´¨é‡æ§åˆ¶æŒ‡æ ‡

| æŒ‡æ ‡       | é˜ˆå€¼ | æ£€æŸ¥æ–¹å¼            |
| ---------- | ---- | ------------------- |
| æ¦‚å¿µæœ‰æ•ˆç‡ | >85% | äººå·¥æŠ½æŸ¥ 100 ä¸ª     |
| å…³ç³»å‡†ç¡®ç‡ | >70% | äººå·¥éªŒè¯ 50 ä¸ª      |
| å»é‡è¦†ç›–ç‡ | >90% | è®¡ç®—åŒä¹‰è¯å¯¹æ•°      |
| å­¤ç«‹èŠ‚ç‚¹ç‡ | <10% | è®¡ç®—åº¦æ•°ä¸º 0 çš„èŠ‚ç‚¹ |
| è‡ªç¯å…³ç³»   | 0    | è‡ªåŠ¨æ£€æµ‹å¹¶ç§»é™¤      |

#### 3.5 å¯æ”¹è¿›ç‚¹

- ğŸ”„ **ä¸»åŠ¨å­¦ä¹ **ï¼šäººå·¥æ ‡æ³¨è¾¹ç•Œæ ·ä¾‹ä¼˜åŒ–é˜ˆå€¼
- ğŸ”„ **è§„åˆ™æŒ–æ˜**ï¼šè‡ªåŠ¨å‘ç°æ•°æ®ä¸­çš„æ¨¡å¼
- ğŸ”„ **å¼‚å¸¸æ£€æµ‹**ï¼šè¯†åˆ«å¼‚å¸¸é«˜/ä½é¢‘å®ä½“
- ğŸ”„ **å®ä½“æ¶ˆæ­§**ï¼šåŒºåˆ†åŒåä¸åŒä¹‰çš„å®ä½“
- ğŸ”„ **å…³ç³»ç±»å‹ç»†åŒ–**ï¼šå°† CO_OCCURS ç»†åˆ†ä¸ºæ›´å…·ä½“çš„è¯­ä¹‰å…³ç³»

---

### é˜¶æ®µ 4ï¼šè¯­ä¹‰ä½“æ£€ä¸å›¾è°±ä¼˜åŒ–

**æ ¸å¿ƒæ¨¡å—**ï¼š`bio_semantic_review.py`ã€`fix_semantic_triples.py`

#### 4.1 èŠ‚ç‚¹ç±»å‹æ¨æ–­

**åŸºäºè§„åˆ™çš„åˆ†ç±»å™¨**ï¼š

```python
def infer_node_type(name: str) -> str:
    n = name.lower()

    # ä¼˜å…ˆçº§è§„åˆ™ï¼ˆä»é«˜åˆ°ä½ï¼‰
    if "bursaphelenchus" in n:
        return "Pathogen"

    if "pine wilt" in n:
        return "Disease"

    if any(x in n for x in ["pinus", "pine", "tree"]):
        return "Host"

    if "monochamus" in n or "beetle" in n:
        return "Vector"

    if any(x in n for x in ["control", "trap", "é˜²æ²»"]):
        return "ControlMeasure"

    if any(x in n for x in ["symptom", "wilt", "ç—‡çŠ¶"]):
        return "Symptom"

    if any(x in n for x in ["province", "city", "area"]):
        return "Region"

    if any(x in n for x in ["temperature", "climate"]):
        return "EnvironmentalFactor"

    if any(x in n for x in ["spectral", "algorithm"]):
        return "Technology"

    return "Other"
```

**ç±»å‹åˆ†å¸ƒéªŒè¯**ï¼š

```python
# é¢„æœŸåˆ†å¸ƒï¼ˆåŸºäºé¢†åŸŸçŸ¥è¯†ï¼‰
expected_distribution = {
    "Pathogen": 5-10,
    "Host": 10-20,
    "Vector": 3-8,
    "Disease": 1-3,
    "Symptom": 5-15,
    "ControlMeasure": 3-10,
    "Region": 5-15,
    "EnvironmentalFactor": 3-8,
    "Technology": 3-8,
    "Other": <20
}
```

#### 4.2 å…³ç³»è¯­ä¹‰æ£€æŸ¥

**å…³ç³»-èŠ‚ç‚¹ç±»å‹ç™½åå•**ï¼š

```python
VALID_RELATION_PATTERNS = {
    "INFECTS": [
        ("Pathogen", "Host"),     # ç—…åŸæ„ŸæŸ“å¯„ä¸» âœ“
        ("Pathogen", "Vector"),   # ç—…åŸæ„ŸæŸ“åª’ä»‹ âœ“
    ],
    "TRANSMITS": [
        ("Vector", "Pathogen"),   # åª’ä»‹ä¼ æ’­ç—…åŸ âœ“
        ("Vector", "Disease"),    # åª’ä»‹ä¼ æ’­ç–¾ç—… âœ“
    ],
    "PARASITIZES": [
        ("Pathogen", "Host"),     # ç—…åŸå¯„ç”Ÿäºå¯„ä¸» âœ“
        ("Vector", "Host"),       # åª’ä»‹å¯„ç”Ÿäºå¯„ä¸» âœ“
    ],
    "CAUSES": [
        ("Pathogen", "Symptom"),  # ç—…åŸå¼•èµ·ç—‡çŠ¶ âœ“
        ("Disease", "Symptom"),   # ç–¾ç—…å¼•èµ·ç—‡çŠ¶ âœ“
    ],
    "TREATS": [
        ("ControlMeasure", "Disease"),  # æªæ–½æ²»ç–—ç–¾ç—… âœ“
        ("ControlMeasure", "Pathogen"), # æªæ–½å¯¹æŠ—ç—…åŸ âœ“
    ],
    "DISTRIBUTED_IN": [
        ("Pathogen", "Region"),   # ç—…åŸåˆ†å¸ƒäºåœ°åŒº âœ“
        ("Host", "Region"),       # å¯„ä¸»åˆ†å¸ƒäºåœ°åŒº âœ“
        ("Vector", "Region"),     # åª’ä»‹åˆ†å¸ƒäºåœ°åŒº âœ“
    ]
}
```

**è¯­ä¹‰å¼‚å¸¸æ£€æµ‹**ï¼š

```python
def check_semantic_validity(head_type, relation, tail_type):
    """æ£€æŸ¥ä¸‰å…ƒç»„è¯­ä¹‰åˆç†æ€§"""

    # 1. æ£€æŸ¥ç™½åå•
    if (head_type, tail_type) not in VALID_RELATION_PATTERNS[relation]:
        issue = f"Invalid pattern: {head_type} -{relation}-> {tail_type}"

    # 2. æ£€æµ‹æ–¹å‘é”™è¯¯
    if relation == "INFECTS" and head_type == "Host":
        suggestion = "Reverse direction"

    # 3. æ£€æµ‹è¯­ä¹‰å†²çª
    if relation == "TRANSMITS" and tail_type == "Host":
        issue = "TRANSMITS should target Pathogen/Disease"

    # 4. æ£€æµ‹è‡ªç¯
    if head == tail:
        issue = "Self-loop detected"
        action = "DELETE"
```

#### 4.3 è‡ªåŠ¨ä¿®æ­£ç­–ç•¥

**æ–¹å‘çº æ­£**ï¼š

```python
AUTO_REVERSE_RULES = {
    # (å…³ç³», é”™è¯¯æ–¹å‘) â†’ æ­£ç¡®æ–¹å‘
    ("INFECTS", ("Host", "Pathogen")):
        ("Pathogen", "INFECTS", "Host"),

    ("TRANSMITS", ("Disease", "Vector")):
        ("Vector", "TRANSMITS", "Disease"),

    ("TREATS", ("Disease", "ControlMeasure")):
        ("ControlMeasure", "TREATS", "Disease"),
}

# ä»…åœ¨éå¸¸ç¡®å®šçš„æƒ…å†µä¸‹è‡ªåŠ¨çº æ­£
confidence_threshold = 0.95
```

**å…³ç³»ç±»å‹æ›¿æ¢**ï¼š

```python
RELATION_TYPE_FIXES = {
    # è¿‡äºé€šç”¨çš„å…³ç³» â†’ æ›´å…·ä½“çš„å…³ç³»
    ("Host", "CO_OCCURS_WITH", "Vector"): "HOSTS",
    ("Pathogen", "CO_OCCURS_WITH", "Symptom"): "CAUSES",
    ("ControlMeasure", "CO_OCCURS_WITH", "Disease"): "TREATS",
}
```

#### 4.4 è´¨é‡æŠ¥å‘Šç”Ÿæˆ

**è¯­ä¹‰é—®é¢˜åˆ†ç±»**ï¼š

```python
issues_df = pd.DataFrame(columns=[
    'triple_id',          # ä¸‰å…ƒç»„ ID
    'head', 'relation', 'tail',
    'head_type', 'tail_type',
    'issue_type',         # é—®é¢˜ç±»å‹
    'severity',           # ä¸¥é‡ç¨‹åº¦ (HIGH/MEDIUM/LOW)
    'suggestion',         # ä¿®æ­£å»ºè®®
    'auto_fixed'          # æ˜¯å¦è‡ªåŠ¨ä¿®æ­£
])

# é—®é¢˜ç±»å‹ç»Ÿè®¡
issue_types = [
    "INVALID_PATTERN",    # ä¸ç¬¦åˆç™½åå•
    "WRONG_DIRECTION",    # æ–¹å‘é”™è¯¯
    "SELF_LOOP",          # è‡ªç¯
    "ORPHAN_NODE",        # å­¤ç«‹èŠ‚ç‚¹
    "LOW_CONFIDENCE",     # ä½ç½®ä¿¡åº¦
]
```

**æ¸…æ´—æŠ¥å‘Šç¤ºä¾‹**ï¼š

```
=== è¯­ä¹‰ä½“æ£€æŠ¥å‘Š ===
æ£€æŸ¥æ—¶é—´: 2025-11-16
åŸå§‹ä¸‰å…ƒç»„: 365 æ¡
æ£€æµ‹é—®é¢˜: 47 æ¡

é—®é¢˜åˆ†ç±»:
  - æ–¹å‘é”™è¯¯: 12 (è‡ªåŠ¨ä¿®æ­£: 8)
  - æ— æ•ˆæ¨¡å¼: 23 (äººå·¥å®¡æ ¸)
  - è‡ªç¯: 5 (è‡ªåŠ¨åˆ é™¤)
  - å­¤ç«‹èŠ‚ç‚¹: 7 (ä¿ç•™ä½†æ ‡è®°)

æ¸…æ´—åä¸‰å…ƒç»„: 352 æ¡
è´¨é‡æå‡: çº¦ 15%
```

#### 4.5 å¯æ”¹è¿›ç‚¹

- ğŸ”„ **æœºå™¨å­¦ä¹ åˆ†ç±»å™¨**ï¼šä½¿ç”¨ GNN è‡ªåŠ¨å­¦ä¹ èŠ‚ç‚¹ç±»å‹
- ğŸ”„ **å…³ç³»éªŒè¯æ¨¡å‹**ï¼šè®­ç»ƒåˆ†ç±»å™¨åˆ¤æ–­å…³ç³»åˆç†æ€§
- ğŸ”„ **çŸ¥è¯†å›¾è°±åµŒå…¥**ï¼šTransE/RotatE æ£€æµ‹ä¸ä¸€è‡´æ€§
- ğŸ”„ **è§„åˆ™å­¦ä¹ **ï¼šä»æ•°æ®ä¸­è‡ªåŠ¨æŒ–æ˜è¯­ä¹‰è§„åˆ™
- ğŸ”„ **äº¤äº’å¼å®¡æ ¸ç•Œé¢**ï¼šå¯è§†åŒ–å®¡æ ¸å’Œä¿®æ­£å·¥å…·

---

## çŸ¥è¯†å›¾è°±è®¾è®¡

### å®ä½“ç±»å‹ï¼ˆæ¦‚å¿µå±‚é¢ï¼‰

ä¸‹è¡¨ä¸ºå›¾è°±ä¸­å¸¸è§çš„å®ä½“ç±»å‹åŠç¤ºä¾‹ï¼š

| ç±»å‹       | è¯´æ˜       | ç¤ºä¾‹                         |
| ---------- | ---------- | ---------------------------- |
| Disease    | ç–¾ç—…       | pine wilt disease            |
| Pathogen   | ç—…åŸä½“     | bursaphelenchus xylophilus   |
| Host       | å¯„ä¸»       | pinus thunbergiiã€é©¬å°¾æ¾     |
| Vector     | åª’ä»‹       | monochamus alternatus ç­‰å¤©ç‰› |
| Symptom    | ç—‡çŠ¶       | å¶ç‰‡å˜è‰²ã€è½å¶               |
| Control    | é˜²æ²»æªæ–½   | è¯±æ•å™¨ã€ç”Ÿç‰©é˜²æ²»ã€é˜²æ²»       |
| Technology | æŠ€æœ¯ä¸æ–¹æ³• | Sentinel-2ã€é«˜å…‰è°±æ•°æ®       |
| Location   | åœ°ç‚¹       | æ³°å±±é£æ™¯åŒºã€å·´å±±ã€ç–«åŒº       |
| Other      | å…¶ä»–æ¦‚å¿µ   | æ—ä¸šã€å…‰è°±ã€æ³¢æ®µé€‰æ‹©ç®—æ³•ç­‰   |

ä¸åŒè„šæœ¬å’Œå¯¼å…¥æ–¹å¼ä¸‹ï¼Œå…·ä½“çš„æ ‡ç­¾å‘½åä¼šç•¥æœ‰å·®å¼‚ï¼Œä½†æ•´ä½“è®¾è®¡å›´ç»•ä¸Šè¿°å‡ ç±»ã€‚

### å…³ç³»ç±»å‹ï¼ˆè¯­ä¹‰å±‚é¢ï¼‰

åœ¨æœ€ç»ˆå›¾è°±ä¸­ï¼Œé™¤äº†å…±ç°å…³ç³»å¤–ï¼Œè¿˜åŒ…å«å¤šç±»è¯­ä¹‰å…³ç³»ï¼Œä¾‹å¦‚ï¼š

- `PARASITIZES`ï¼ˆå¯„ç”Ÿï¼‰ï¼šåª’ä»‹æˆ–ç—…åŸä½“å¯„ç”Ÿåœ¨å¯„ä¸»ä¸Š
- `INFECTS`ï¼ˆæ„ŸæŸ“ï¼‰ï¼šç—…åŸä½“å¯¹å¯„ä¸»çš„æ„ŸæŸ“å…³ç³»
- `CAUSES` / `SYMPTOM`ï¼ˆå¼•èµ· / ç—‡çŠ¶ï¼‰ï¼šç–¾ç—…ä¸ç—‡çŠ¶ä¹‹é—´çš„è”ç³»
- `TRANSMITS`ï¼ˆä¼ æ’­ï¼‰ï¼šåª’ä»‹ä¼ æ’­ç—…åŸä½“æˆ–ç–¾ç—…
- `DISTRIBUTED_IN`ï¼ˆåˆ†å¸ƒäºï¼‰ï¼šç–¾ç—…æˆ–åª’ä»‹åœ¨åœ°åŒºä¸Šçš„åˆ†å¸ƒ
- `AFFECTS`ï¼ˆå½±å“ï¼‰ï¼šç¯å¢ƒæˆ–æŠ€æœ¯å› ç´ å¯¹ç—…å®³çš„å½±å“
- `TREATS` / `CONTROLS`ï¼ˆæ²»ç–— / é˜²æ²»ï¼‰ï¼šé˜²æ²»æªæ–½ä¸ç—…å®³æˆ–ç—…åŸä½“ä¹‹é—´çš„å…³ç³»
- `USED_FOR` / `MONITORS`ï¼ˆç”¨äº / ç›‘æµ‹ï¼‰ï¼šæŠ€æœ¯ä¸ç›‘æµ‹ä»»åŠ¡ä¹‹é—´çš„å…³ç³»
- `CO_OCCURS_WITH`ï¼ˆå…±ç°ï¼‰ï¼šæ–‡çŒ®ä¸­å…±åŒå‡ºç°çš„æ¦‚å¿µï¼Œç”¨äºè¡¥å……èƒŒæ™¯è¿æ¥

---

## ç›®å½•ç»“æ„ä¸æ ¸å¿ƒè„šæœ¬

é¡¹ç›®æ ¹ç›®å½•çš„ä¸»è¦ç»“æ„å¦‚ä¸‹ï¼ˆç®€åŒ–ï¼‰ï¼š

```text
PWD/
â”œâ”€â”€ README.md                  # é¡¹ç›®è¯´æ˜ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â”œâ”€â”€ requirements.txt           # Python ä¾èµ–
â”œâ”€â”€ .gitignore                 # Git å¿½ç•¥è§„åˆ™
â”‚
â”œâ”€â”€ docs/                      # æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.txt  # é¡¹ç›®ç»“æ„è¯´æ˜
â”‚   â””â”€â”€ PWD_Knowledge_Graph_Analysis.html  # åˆ†ææŠ¥å‘ŠHTMLç‰ˆæœ¬
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter Notebooks
â”‚   â”œâ”€â”€ PWD_Knowledge_Graph_Analysis.ipynb  # ä¸»åˆ†æç¬”è®°æœ¬
â”‚   â””â”€â”€ PWD_KG_Notebook.ipynb  # çŸ¥è¯†å›¾è°±ç¬”è®°æœ¬
â”‚
â”œâ”€â”€ æ ¸å¿ƒè„šæœ¬ï¼ˆä¸»æµç¨‹ï¼‰
â”‚   â”œâ”€â”€ main.py                # ä¸»å…¥å£ï¼Œæ•´åˆå¢å¼ºç®¡é“ä¸ Neo4j ç®¡ç†
â”‚   â”œâ”€â”€ enhanced_pipeline.py   # LLM æ¦‚å¿µä¸å…³ç³»æŠ½å–ç®¡é“
â”‚   â”œâ”€â”€ concept_extractor.py   # æ¦‚å¿µä¸å…³ç³»æŠ½å–
â”‚   â”œâ”€â”€ concept_deduplicator.py # åµŒå…¥å¼å»é‡ä¸åˆå¹¶
â”‚   â”œâ”€â”€ data_cleaner.py        # æ•°æ®æ¸…æ´—ä¸è§„èŒƒåŒ–
â”‚   â”œâ”€â”€ neo4j_generator.py     # ç”Ÿæˆ Neo4j å¯¼å…¥æ–‡ä»¶
â”‚   â”œâ”€â”€ neo4j_manager.py       # Neo4j å¤‡ä»½ã€æ¸…ç©ºä¸å›æ»š
â”‚   â”œâ”€â”€ pdf_extractor.py       # PDF æ–‡æœ¬æå–
â”‚   â”œâ”€â”€ ocr_processor.py       # OCR å¤„ç†
â”‚   â”œâ”€â”€ entity_linker.py       # å®ä½“é“¾æ¥
â”‚   â”œâ”€â”€ parallel_processor.py  # å¹¶è¡Œå¤„ç†
â”‚   â”œâ”€â”€ bio_semantic_review.py # ä¸‰å…ƒç»„è¯­ä¹‰ä½“æ£€
â”‚   â””â”€â”€ import_to_neo4j_final.py # ä½¿ç”¨ä¸‰å…ƒç»„å¯¼å…¥æœ€ç»ˆå›¾è°±
â”‚
â”œâ”€â”€ scripts/                   # è¾…åŠ©è„šæœ¬
â”‚   â”œâ”€â”€ workflow/              # å·¥ä½œæµè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ run_complete_workflow.sh  # ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹
â”‚   â”‚   â”œâ”€â”€ check_progress.sh  # è¿è¡Œè¿›åº¦æ£€æŸ¥
â”‚   â”‚   â”œâ”€â”€ clean_project.sh   # è¾“å‡ºä¸ç¼“å­˜æ¸…ç†
â”‚   â”‚   â””â”€â”€ organize_project.sh # é¡¹ç›®æ–‡ä»¶æ•´ç†
â”‚   â””â”€â”€ utils/                 # å·¥å…·è„šæœ¬
â”‚       â”œâ”€â”€ export_for_review.py  # å¯¼å‡ºå®¡æŸ¥æ–‡ä»¶
â”‚       â”œâ”€â”€ export_triples.py  # å¯¼å‡ºä¸‰å…ƒç»„
â”‚       â”œâ”€â”€ export_neo4j_to_csv.py # ä»æ•°æ®åº“å¯¼å‡º CSV
â”‚       â”œâ”€â”€ auto_disambiguate.py # è‡ªåŠ¨æ¶ˆæ­§
â”‚       â”œâ”€â”€ cache_manager.py   # ç¼“å­˜ç®¡ç†
â”‚       â”œâ”€â”€ config_loader.py   # é…ç½®åŠ è½½
â”‚       â”œâ”€â”€ logger_config.py   # æ—¥å¿—é…ç½®
â”‚       â””â”€â”€ visualize_neo4j_graph.py # Neo4j å›¾å¯è§†åŒ–
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml            # ä¸»é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ domain_dict.json       # é¢†åŸŸè¯å…¸
â”‚   â””â”€â”€ stopwords.txt          # åœç”¨è¯
â”‚
â”œâ”€â”€ output/                    # è¾“å‡ºç›®å½•
â”‚   â”œâ”€â”€ concepts*.csv          # æ¦‚å¿µç›¸å…³ä¸­é—´ç»“æœ
â”‚   â”œâ”€â”€ relationships*.csv     # å…³ç³»ç›¸å…³ä¸­é—´ç»“æœ
â”‚   â”œâ”€â”€ entities_clean.csv     # æ¸…æ´—åå®ä½“
â”‚   â”œâ”€â”€ relations_clean.csv    # æ¸…æ´—åå…³ç³»
â”‚   â”œâ”€â”€ neo4j_import/          # Neo4j å¯¼å…¥æ–‡ä»¶ä¸è„šæœ¬
â”‚   â”œâ”€â”€ triples/               # ä¸‰å…ƒç»„ç›¸å…³ä¸­é—´ç»“æœ
â”‚   â”œâ”€â”€ statistics_report.txt  # æŠ½å–/æ¸…æ´—é˜¶æ®µç»Ÿè®¡
â”‚   â””â”€â”€ *.md/*.json            # æ•°æ®æ£€æŸ¥ä¸å¯¼å…¥æŠ¥å‘Š
â”‚
â”œâ”€â”€ archive/                   # å¼€å‘è¿‡ç¨‹å­˜æ¡£
â”‚   â”œâ”€â”€ scripts/               # è°ƒè¯•å’Œä¸­é—´ç‰ˆæœ¬è„šæœ¬
â”‚   â””â”€â”€ docs/                  # æ—§æ–‡æ¡£å’ŒæŠ¥å‘Š
â”‚
â”œâ”€â”€ æ–‡çŒ®/                      # PDF æ–‡çŒ®ç›®å½•
â””â”€â”€ venv/                      # è™šæ‹Ÿç¯å¢ƒï¼ˆä¸çº³å…¥ç‰ˆæœ¬æ§åˆ¶ï¼‰
```

æ›´ç»†è‡´çš„è¯´æ˜å¯å‚è€ƒ `docs/PROJECT_STRUCTURE.txt`ã€‚

---

## æ ¸å¿ƒæŠ€æœ¯ç»„ä»¶è¯¦è§£

### é…ç½®ç®¡ç†ç³»ç»Ÿ

**é…ç½®æ–‡ä»¶**ï¼š`config/config.yaml`ã€`config_loader.py`

#### é…ç½®æ¶æ„

```yaml
# PDF æå–é…ç½®
pdf:
  input_directory: ./æ–‡çŒ®
  output_directory: ./output/extracted_texts
  enable_cache: true # å¯ç”¨ MD5 ç¼“å­˜
  cache_directory: ./cache/pdf
  parallel_workers: 8 # å¹¶è¡Œè¿›ç¨‹æ•°
  enable_ocr: false # OCR æŒ‰éœ€å¯ç”¨
  ocr_engine: tesseract # tesseract | paddle

# å®ä½“è¯†åˆ«é…ç½®
entity:
  enable_tfidf: true # TF-IDF å…³é”®è¯æå–
  enable_yake: true # YAKE ç®—æ³•
  enable_keybert: true # KeyBERTï¼ˆåŸºäº BERTï¼‰
  enable_spacy: true # spaCy NER
  domain_dict_file: ./config/domain_dict.json
  min_frequency: 2 # æœ€å°è¯é¢‘

# å…³ç³»æŠ½å–é…ç½®
relation:
  enable_pattern_matching: true # æ¨¡å¼åŒ¹é…
  enable_cooccurrence: true # å…±ç°åˆ†æ
  window_size: 100 # å…±ç°çª—å£å¤§å°
  min_cooccurrence: 2 # æœ€å°å…±ç°æ¬¡æ•°

# æ•°æ®æ¸…æ´—é…ç½®
cleaning:
  confidence_threshold: 0.65 # ç½®ä¿¡åº¦é˜ˆå€¼
  similarity_threshold: 0.85 # è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
  enable_entity_linking: true # å®ä½“é“¾æ¥
  min_length: 2 # æœ€å°å®ä½“é•¿åº¦
  max_length: 50 # æœ€å¤§å®ä½“é•¿åº¦

# Neo4j æ•°æ®åº“é…ç½®
neo4j:
  uri: neo4j://127.0.0.1:7687 # æœ¬åœ°å®ä¾‹
  user: neo4j
  password: "12345678"
  database: PWD # æ•°æ®åº“å
  enable_backup: true # è‡ªåŠ¨å¤‡ä»½
  backup_directory: ./backups

# LLM é…ç½®
llm:
  provider: ollama # ollama | openai
  model: llama3.2:3b # æ¨¡å‹åç§°
  ollama_host: http://localhost:11434
  max_chunks: 100 # æœ€å¤§å¤„ç†å—æ•°
  chunk_size: 2000 # å—å¤§å°ï¼ˆå­—ç¬¦ï¼‰
  chunk_overlap: 200 # å—é‡å 
  temperature: 0.1 # ç”Ÿæˆæ¸©åº¦
  timeout: 120 # API è¶…æ—¶ï¼ˆç§’ï¼‰

# å»é‡é…ç½®
deduplication:
  similarity_threshold: 0.85 # æ¦‚å¿µå»é‡é˜ˆå€¼
  embedding_model: sentence-transformers/paraphrase-MiniLM-L6-v2
  use_clustering: false # ä½¿ç”¨èšç±»ç®—æ³•

# è¿‡æ»¤é…ç½®
filtering:
  min_importance: 1 # æœ€å°é‡è¦æ€§
  min_connections: 0 # æœ€å°è¿æ¥æ•°

# ç³»ç»Ÿé…ç½®
system:
  enable_cache: true # å…¨å±€ç¼“å­˜å¼€å…³
  enable_parallel: true # å¹¶è¡Œå¤„ç†
  log_level: INFO # DEBUG | INFO | WARNING
  max_workers: 8 # æœ€å¤§å·¥ä½œè¿›ç¨‹
```

#### é…ç½®åŠ è½½æœºåˆ¶

```python
# config_loader.py å®ç°
import yaml
from pathlib import Path
from typing import Dict, Any

class ConfigLoader:
    """é…ç½®åŠ è½½å™¨ï¼Œæ”¯æŒå¤šå±‚çº§é…ç½®åˆå¹¶"""

    def __init__(self, config_path: str = "config/config.yaml"):
        self.config_path = Path(config_path)
        self._config = None
        self._load_config()

    def _load_config(self):
        """åŠ è½½å¹¶éªŒè¯é…ç½®"""
        with open(self.config_path, 'r', encoding='utf-8') as f:
            self._config = yaml.safe_load(f)

        # é»˜è®¤å€¼å¡«å……
        self._apply_defaults()

        # é…ç½®éªŒè¯
        self._validate_config()

    def get(self, key: str, default: Any = None) -> Any:
        """
        è·å–é…ç½®å€¼ï¼Œæ”¯æŒç‚¹å·è·¯å¾„

        Example:
            config.get('llm.model')  # 'llama3.2:3b'
            config.get('pdf.enable_cache')  # True
        """
        keys = key.split('.')
        value = self._config

        for k in keys:
            if isinstance(value, dict):
                value = value.get(k)
            else:
                return default

        return value if value is not None else default
```

#### é…ç½®ä¼˜åŒ–ç­–ç•¥

```python
# åœºæ™¯ 1: å°è§„æ¨¡æµ‹è¯•ï¼ˆå¿«é€ŸéªŒè¯ï¼‰
test_config = {
    'llm.max_chunks': 10,           # ä»…å¤„ç† 10 ä¸ªå—
    'pdf.parallel_workers': 4,      # å‡å°‘å¹¶è¡Œåº¦
    'filtering.min_importance': 3,  # åªä¿ç•™é‡è¦æ¦‚å¿µ
}

# åœºæ™¯ 2: é«˜è´¨é‡ç”Ÿäº§ï¼ˆå‡†ç¡®ç‡ä¼˜å…ˆï¼‰
production_config = {
    'llm.temperature': 0.0,         # ç¡®å®šæ€§è¾“å‡º
    'cleaning.confidence_threshold': 0.75,
    'deduplication.similarity_threshold': 0.90,
    'enable_entity_linking': True,
}

# åœºæ™¯ 3: é«˜å¬å›ï¼ˆè¦†ç›–ç‡ä¼˜å…ˆï¼‰
recall_config = {
    'cleaning.confidence_threshold': 0.5,
    'deduplication.similarity_threshold': 0.80,
    'filtering.min_importance': 0,
}

# åœºæ™¯ 4: å¤§è§„æ¨¡å¤„ç†ï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼‰
speed_config = {
    'pdf.parallel_workers': 16,     # æœ€å¤§å¹¶è¡Œ
    'system.enable_cache': True,    # å¼ºåˆ¶ç¼“å­˜
    'llm.max_chunks': None,         # ä¸é™åˆ¶
    'enable_ocr': False,            # ç¦ç”¨ OCR
}
```

---

### ç¼“å­˜ç®¡ç†ç³»ç»Ÿ

**æ ¸å¿ƒæ¨¡å—**ï¼š`cache_manager.py`

#### ç¼“å­˜æ¶æ„

```python
class CacheManager:
    """å¤šçº§ç¼“å­˜ç®¡ç†å™¨"""

    def __init__(self, cache_dir: str = "./cache"):
        self.cache_dir = Path(cache_dir)

        # ç¼“å­˜åˆ†ç±»
        self.pdf_cache_dir = self.cache_dir / "pdf"
        self.embedding_cache_dir = self.cache_dir / "embeddings"
        self.llm_cache_dir = self.cache_dir / "llm"

        # åˆ›å»ºç›®å½•
        for dir in [self.pdf_cache_dir,
                    self.embedding_cache_dir,
                    self.llm_cache_dir]:
            dir.mkdir(parents=True, exist_ok=True)

    def get_cache_key(self, data: Any, prefix: str = "") -> str:
        """ç”Ÿæˆç¼“å­˜é”®ï¼ˆMD5 hashï¼‰"""
        import hashlib

        if isinstance(data, (str, bytes)):
            content = data.encode() if isinstance(data, str) else data
        else:
            content = str(data).encode()

        hash_key = hashlib.md5(content).hexdigest()
        return f"{prefix}_{hash_key}" if prefix else hash_key
```

#### ç¼“å­˜ç­–ç•¥

| ç¼“å­˜ç±»å‹     | å­˜å‚¨å†…å®¹   | æœ‰æ•ˆæœŸ | å¤§å°é™åˆ¶ |
| ------------ | ---------- | ------ | -------- |
| **PDF ç¼“å­˜** | æå–çš„æ–‡æœ¬ | æ°¸ä¹…   | æ— é™åˆ¶   |
| **åµŒå…¥ç¼“å­˜** | æ¦‚å¿µå‘é‡   | æ°¸ä¹…   | 10GB     |
| **LLM ç¼“å­˜** | API å“åº”   | 7 å¤©   | 5GB      |
| **å¤„ç†ç¼“å­˜** | ä¸­é—´ç»“æœ   | 1 å¤©   | 1GB      |

#### ç¼“å­˜å¤±æ•ˆç­–ç•¥

```python
# 1. åŸºäºæ—¶é—´çš„å¤±æ•ˆ
if (current_time - cache_time) > TTL:
    invalidate_cache()

# 2. åŸºäºç‰ˆæœ¬çš„å¤±æ•ˆ
cache_version = "v1.0"
if cache.version != cache_version:
    invalidate_cache()

# 3. åŸºäºå†…å®¹çš„å¤±æ•ˆï¼ˆMD5 æ ¡éªŒï¼‰
if compute_md5(file) != cache.md5:
    invalidate_cache()

# 4. æ‰‹åŠ¨æ¸…ç†
./scripts/workflow/clean_project.sh  # æ¸…ç†æ‰€æœ‰ç¼“å­˜
```

---

### Neo4j æ•°æ®åº“ç®¡ç†

**æ ¸å¿ƒæ¨¡å—**ï¼š`neo4j_manager.py`ã€`import_to_neo4j_final.py`

#### æ•°æ®åº“æ¶æ„è®¾è®¡

```cypher
// èŠ‚ç‚¹æ¨¡å‹
(:Concept {
  name: String,              // æ¦‚å¿µåç§°ï¼ˆå”¯ä¸€ï¼‰
  type: String,              // ç±»å‹ï¼ˆHost/Pathogen/Vector...ï¼‰
  importance: Integer,       // é‡è¦æ€§ 1-5
  connections: Integer,      // è¿æ¥æ•°
  category: String,          // åˆ†ç±»
  source: String,            // æ¥æºæ–‡çŒ®
  created_at: DateTime       // åˆ›å»ºæ—¶é—´
})

// å…³ç³»æ¨¡å‹
()-[r:RELATION_TYPE {
  weight: Float,             // æƒé‡ 0-1
  confidence: Float,         // ç½®ä¿¡åº¦ 0-1
  source: String,            // æ¥æºï¼ˆllm/proximity/ruleï¼‰
  source_pdf: String,        // æ¥æºæ–‡çŒ®
  created_at: DateTime       // åˆ›å»ºæ—¶é—´
}]->()

// ç´¢å¼•å’Œçº¦æŸ
CREATE CONSTRAINT concept_name_unique
FOR (n:Concept) REQUIRE n.name IS UNIQUE;

CREATE INDEX concept_type_index
FOR (n:Concept) ON (n.type);

CREATE INDEX concept_importance_index
FOR (n:Concept) ON (n.importance);
```

#### æ‰¹é‡å¯¼å…¥ä¼˜åŒ–

```python
# ä½¿ç”¨äº‹åŠ¡æ‰¹å¤„ç†
BATCH_SIZE = 1000

def import_nodes_batch(nodes_df, driver):
    """æ‰¹é‡å¯¼å…¥èŠ‚ç‚¹"""
    with driver.session() as session:
        for i in range(0, len(nodes_df), BATCH_SIZE):
            batch = nodes_df[i:i+BATCH_SIZE]

            session.execute_write(
                lambda tx: tx.run("""
                    UNWIND $batch AS row
                    MERGE (n:Concept {name: row.name})
                    SET n.type = row.type,
                        n.importance = row.importance,
                        n.connections = row.connections
                """, batch=batch.to_dict('records'))
            )

# æ€§èƒ½å¯¹æ¯”
# é€æ¡æ’å…¥: 100 èŠ‚ç‚¹ â†’ 60 ç§’
# æ‰¹é‡å¯¼å…¥: 100 èŠ‚ç‚¹ â†’ 2 ç§’  (30x æé€Ÿ)
```

#### å¤‡ä»½ä¸æ¢å¤

```python
class Neo4jManager:
    """Neo4j æ•°æ®åº“ç®¡ç†å™¨"""

    def backup_database(self, backup_dir: str = "./backups"):
        """å¯¼å‡ºæ•°æ®åº“ä¸º Cypher è„šæœ¬"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = f"{backup_dir}/backup_{timestamp}.cypher"

        with self.driver.session() as session:
            # å¯¼å‡ºèŠ‚ç‚¹
            nodes = session.run("MATCH (n) RETURN n")

            # å¯¼å‡ºå…³ç³»
            rels = session.run("MATCH ()-[r]->() RETURN r")

            # ç”Ÿæˆ Cypher è„šæœ¬
            with open(backup_file, 'w') as f:
                # ... å†™å…¥ CREATE è¯­å¥

        return backup_file

    def restore_from_backup(self, backup_file: str):
        """ä»å¤‡ä»½æ¢å¤æ•°æ®åº“"""
        with self.driver.session() as session:
            # æ¸…ç©ºæ•°æ®åº“
            session.run("MATCH (n) DETACH DELETE n")

            # æ‰§è¡Œå¤‡ä»½è„šæœ¬
            with open(backup_file, 'r') as f:
                cypher_script = f.read()
                session.run(cypher_script)
```

---

### æ—¥å¿—ç³»ç»Ÿ

**æ ¸å¿ƒæ¨¡å—**ï¼š`logger_config.py`

#### æ—¥å¿—æ¶æ„

```python
import logging
from logging.handlers import RotatingFileHandler

def setup_logger(name: str, level: str = "INFO"):
    """é…ç½®åˆ†å±‚æ—¥å¿—ç³»ç»Ÿ"""

    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, level))

    # æ§åˆ¶å° Handlerï¼ˆå½©è‰²è¾“å‡ºï¼‰
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(ColoredFormatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    ))

    # æ–‡ä»¶ Handlerï¼ˆæ»šåŠ¨æ—¥å¿—ï¼‰
    file_handler = RotatingFileHandler(
        f'logs/{name}.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
    file_handler.setFormatter(logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    ))

    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

    return logger
```

#### æ—¥å¿—çº§åˆ«ä½¿ç”¨

```python
# DEBUG: è°ƒè¯•ä¿¡æ¯ï¼ˆè¯¦ç»†çš„å˜é‡å€¼ï¼‰
logger.debug(f"Embedding shape: {embeddings.shape}")

# INFO: è¿›åº¦ä¿¡æ¯ï¼ˆç”¨æˆ·å…³å¿ƒçš„äº‹ä»¶ï¼‰
logger.info(f"Processed {i}/{total} chunks")

# WARNING: è­¦å‘Šï¼ˆä¸å½±å“æµç¨‹ä½†éœ€æ³¨æ„ï¼‰
logger.warning(f"Low confidence: {confidence:.2f}")

# ERROR: é”™è¯¯ï¼ˆå½±å“åŠŸèƒ½ä½†å¯æ¢å¤ï¼‰
logger.error(f"Failed to parse JSON: {e}")

# CRITICAL: ä¸¥é‡é”™è¯¯ï¼ˆç¨‹åºæ— æ³•ç»§ç»­ï¼‰
logger.critical(f"Database connection lost")
```

---

### å¹¶è¡Œå¤„ç†æ¡†æ¶

**æ ¸å¿ƒæ¨¡å—**ï¼š`parallel_processor.py`

#### å¹¶è¡Œç­–ç•¥

```python
from multiprocessing import Pool, cpu_count
from concurrent.futures import ProcessPoolExecutor

class ParallelProcessor:
    """å¹¶è¡Œå¤„ç†æ¡†æ¶"""

    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers or cpu_count()

    def map(self, func, items, chunksize=1):
        """å¹¶è¡Œæ˜ å°„"""
        with Pool(self.max_workers) as pool:
            return pool.map(func, items, chunksize=chunksize)

    def starmap(self, func, items):
        """å¹¶è¡Œæ˜ å°„ï¼ˆå¤šå‚æ•°ï¼‰"""
        with Pool(self.max_workers) as pool:
            return pool.starmap(func, items)

# ä½¿ç”¨ç¤ºä¾‹
processor = ParallelProcessor(max_workers=8)

# PDF æå–å¹¶è¡ŒåŒ–
pdf_files = glob.glob("æ–‡çŒ®/*.pdf")
texts = processor.map(extract_pdf, pdf_files)

# LLM æ¨ç†å¹¶è¡ŒåŒ–ï¼ˆè°¨æ…ä½¿ç”¨ï¼Œå¯èƒ½è¶…å‡º API é™åˆ¶ï¼‰
chunks = split_into_chunks(text)
results = processor.map(llm_extract, chunks)
```

#### æ€§èƒ½è°ƒä¼˜

| åœºæ™¯     | å»ºè®®è¿›ç¨‹æ•°     | è¯´æ˜     |
| -------- | -------------- | -------- |
| PDF æå– | CPU æ ¸å¿ƒæ•°     | I/O å¯†é›† |
| æ–‡æœ¬å¤„ç† | CPU æ ¸å¿ƒæ•° Ã— 2 | è®¡ç®—å¯†é›† |
| LLM è°ƒç”¨ | 2-4            | API é™æµ |
| åµŒå…¥è®¡ç®— | CPU æ ¸å¿ƒæ•°     | å†…å­˜å¯†é›† |

---

### é”™è¯¯å¤„ç†ä¸é‡è¯•

#### é‡è¯•è£…é¥°å™¨

```python
from functools import wraps
import time

def retry(max_attempts=3, delay=1, backoff=2):
    """é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            attempt = 0
            current_delay = delay

            while attempt < max_attempts:
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    attempt += 1
                    if attempt >= max_attempts:
                        raise

                    logger.warning(
                        f"Attempt {attempt} failed: {e}. "
                        f"Retrying in {current_delay}s..."
                    )
                    time.sleep(current_delay)
                    current_delay *= backoff

        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@retry(max_attempts=3, delay=2, backoff=2)
def call_llm_api(text):
    response = requests.post(api_url, json={'text': text})
    response.raise_for_status()
    return response.json()
```

---

## é…ç½®è°ƒä¼˜å»ºè®®

### åœºæ™¯åŒ–é…ç½®

```python
# åœºæ™¯ 1: å¼€å‘è°ƒè¯•
DEBUG_CONFIG = {
    'llm.max_chunks': 5,
    'pdf.parallel_workers': 2,
    'system.log_level': 'DEBUG',
}

# åœºæ™¯ 2: ç”Ÿäº§ç¯å¢ƒ
PRODUCTION_CONFIG = {
    'llm.max_chunks': None,
    'pdf.parallel_workers': 16,
    'cleaning.confidence_threshold': 0.75,
    'system.log_level': 'INFO',
}

# åœºæ™¯ 3: ä½èµ„æºç¯å¢ƒ
LOW_RESOURCE_CONFIG = {
    'pdf.parallel_workers': 2,
    'system.enable_parallel': False,
    'deduplication.embedding_model': 'tfidf',  # ä½¿ç”¨è½»é‡æ¨¡å‹
}
```

### æ€§èƒ½è°ƒä¼˜æ£€æŸ¥æ¸…å•

- [ ] å¯ç”¨ç¼“å­˜æœºåˆ¶
- [ ] è°ƒæ•´å¹¶è¡Œè¿›ç¨‹æ•°
- [ ] ä¼˜åŒ– LLM è°ƒç”¨æ‰¹æ¬¡
- [ ] ä½¿ç”¨é€‚å½“çš„åµŒå…¥æ¨¡å‹
- [ ] å®šæœŸæ¸…ç†æ—¥å¿—å’Œç¼“å­˜
- [ ] ç›‘æ§å†…å­˜ä½¿ç”¨
- [ ] è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´

---

## Neo4j ä½¿ç”¨ä¸åˆ†æ

- åŸºæœ¬è¿æ¥ä¿¡æ¯å’Œå¸¸ç”¨æŸ¥è¯¢ç¤ºä¾‹è§ï¼š`NEO4J_USAGE_GUIDE.md`
- å¯¼å…¥å®Œæˆåï¼Œå¯åœ¨ Neo4j Browser ä¸­ï¼š
  - æŒ‰èŠ‚ç‚¹/å…³ç³»ç±»å‹æµè§ˆæ•´ä½“ç»“æ„
  - æŸ¥çœ‹åº¦æ•°æœ€é«˜çš„èŠ‚ç‚¹ã€æƒé‡è¾ƒé«˜çš„å…³ç³»
  - é€šè¿‡æœ€çŸ­è·¯å¾„å’Œå­å›¾æŸ¥è¯¢åˆ†æä¼ æ’­é“¾è·¯

å…¸å‹æŸ¥è¯¢ç¤ºä¾‹ï¼ˆèŠ‚é€‰ï¼‰ï¼š

```cypher
// æŸ¥çœ‹èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ
MATCH (n)
RETURN n.type AS node_type, count(*) AS count
ORDER BY count DESC;

// æŸ¥çœ‹å…³ç³»ç±»å‹åˆ†å¸ƒ
MATCH ()-[r]->()
RETURN type(r) AS rel_type, count(*) AS count
ORDER BY count DESC;

// æŸ¥è¯¢ç—…åŸä½“åˆ°å¯„ä¸»çš„ä¼ æ’­è·¯å¾„
MATCH path = (p:Pathogen)-[*1..4]-(h:Host)
RETURN p.name, h.name, length(path) AS path_length
LIMIT 10;
```

æ›´å®Œæ•´çš„æŸ¥è¯¢å’Œå¯è§†åŒ–å»ºè®®è¯·å‚è€ƒ `NEO4J_USAGE_GUIDE.md`ã€‚

---

## Neo4j å®æ—¶ç»Ÿè®¡ï¼ˆç¤ºä¾‹ï¼‰

ç»Ÿè®¡æ—¶é—´ï¼š2025-11-16ï¼ˆåŸºäºå½“å‰é»˜è®¤æ•°æ®åº“ï¼‰

æŸ¥è¯¢è¯­å¥ï¼š

```cypher
// èŠ‚ç‚¹å’Œå…³ç³»æ€»æ•°
MATCH (n) RETURN count(n) AS node_count;
MATCH ()-[r]->() RETURN count(r) AS rel_count;

// èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒï¼ˆæŒ‰ n.type æˆ–æ ‡ç­¾ï¼‰
MATCH (n)
RETURN coalesce(n.type, head(labels(n))) AS type, count(*) AS count
ORDER BY count DESC;

// å…³ç³»ç±»å‹åˆ†å¸ƒ
MATCH ()-[r]->()
RETURN type(r) AS type, count(*) AS count
ORDER BY count DESC;
```

å½“å‰ç»“æœå¿«ç…§ï¼š

- èŠ‚ç‚¹æ€»æ•°ï¼š59
- å…³ç³»æ€»æ•°ï¼š365

èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒï¼š

- Otherï¼š18
- Hostï¼š16
- Locationï¼š10
- Vectorï¼š5
- Technologyï¼š5
- Controlï¼š3
- Diseaseï¼š1
- Pathogenï¼š1

å…³ç³»ç±»å‹åˆ†å¸ƒï¼ˆæŒ‰æ¡æ•°ä»é«˜åˆ°ä½ï¼‰ï¼š

- CO_OCCURS_WITHï¼š299
- RELATED_TOï¼š12
- PARASITIZESï¼š6
- TREATSï¼š5ï¼ŒDISTRIBUTED_INï¼š5
- AFFECTSï¼š4
- TRANSMITS / INFECTS / FEEDS_ON / LOCATED_IN / USED_FOR / CONTAINS / SYMPTOM_OFï¼šå„ 3
- CARRIES / COMPARES_WITH / CONTROLS / CAUSES / APPLIES_TOï¼šå„ 2
- COMPETES_WITH / MONITORS / COMPONENT_OFï¼šå„ 1

---

## æ€§èƒ½ä¸æ³¨æ„äº‹é¡¹

- å¤„ç†è§„æ¨¡ï¼šå½“å‰é…ç½®ä¸‹ï¼Œå¤„ç†åå‡ ç¯‡ PDFï¼ˆçº¦å‡ å MBï¼‰åœ¨ä¸€å°æ™®é€šç¬”è®°æœ¬ä¸Šè€—æ—¶çº¦å‡ ååˆ†é’Ÿï¼Œä¾èµ–æœ¬åœ° LLM æ¨ç†é€Ÿåº¦
- è¿è¡Œè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆè¾ƒå¤šä¸­é—´ CSV/JSON æ–‡ä»¶ï¼Œå»ºè®®å®šæœŸä½¿ç”¨ `scripts/workflow/clean_project.sh` æ¸…ç†
- LLM æŠ½å–ç»“æœéš¾å…åŒ…å«å™ªå£°å’Œè¾¹ç¼˜æ¦‚å¿µï¼Œæœ€ç»ˆå›¾è°±æ˜¯åœ¨å¤šè½®è¿‡æ»¤å’Œè¯­ä¹‰ä½“æ£€åå¾—åˆ°ï¼Œå…³é”®ç»“è®ºå»ºè®®ç»“åˆé¢†åŸŸçŸ¥è¯†å¤æ ¸

---

## è®¸å¯è¯åŠç”¨é€”

æœ¬é¡¹ç›®ä»…ç”¨äºè¯¾ç¨‹å­¦ä¹ å’Œå­¦æœ¯ç ”ç©¶ï¼Œä¸ç”¨äºç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ã€‚
