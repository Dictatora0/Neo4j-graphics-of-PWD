#!/usr/bin/env python3
"""
åº”ç”¨æœ€ç»ˆçš„å®ä½“åˆå¹¶å’Œé‡æ–°åˆ†ç±»
"""
import pandas as pd
import json
import os

print("="*80)
print("åº”ç”¨æœ€ç»ˆåˆå¹¶å’Œé‡æ–°åˆ†ç±»")
print("="*80)

# åŠ è½½æ•°æ®
concepts_df = pd.read_csv('output/concepts_disambiguated.csv')
relationships_df = pd.read_csv('output/relationships_disambiguated.csv')

print(f"\nåŸå§‹æ•°æ®:")
print(f"  å®ä½“: {len(concepts_df)} ä¸ª")
print(f"  å…³ç³»: {len(relationships_df)} ä¸ª")

# ============================================================================
# 1. å®šä¹‰éœ€è¦åˆå¹¶çš„å®ä½“å¯¹
# ============================================================================
merges = {
    # Sentinel-2 ç³»åˆ—åˆå¹¶
    'sentinel-2': 'sentinel-2 å«æ˜Ÿé¥æ„Ÿå½±åƒ',
    'sentinel-2 å«æ˜Ÿå½±åƒ': 'sentinel-2 å«æ˜Ÿé¥æ„Ÿå½±åƒ',
    
    # å¤©ç‰›ç§ç±»åˆå¹¶
    'monochamus ahernatus': 'monochamus alternatus',  # è¿™ä¸¤ä¸ªå¯èƒ½æ˜¯æ‹¼å†™é”™è¯¯
    'rusticus': 'arhopalus rusticus',
    'äº‘æ‰å°å¢¨å¤©ç‰›': 'äº‘æ‰èŠ±å¢¨å¤©ç‰›',  # å¯èƒ½æ˜¯åŒä¸€ç‰©ç§çš„ä¸åŒå«æ³•
    
    # ä¼´ç”Ÿç»†èŒåˆå¹¶
    'ä¼´ç”Ÿç»†èŒ': 'æ¾æçº¿è™«ä¼´ç”Ÿç»†èŒ',
    
    # é«˜å…‰è°±æ•°æ®åˆå¹¶
    'æ— äººæœºé«˜å…‰è°±': 'æ— äººæœºé«˜å…‰è°±æ•°æ®',
    'é«˜å…‰è°±æ•°æ®': 'æ— äººæœºé«˜å…‰è°±æ•°æ®',
    
    # æ—åœ°ç±»å‹åˆå¹¶
    'è½å¶é˜”å¶æ—': 'æ¸©å¸¦è½å¶é˜”å¶æ—',
    
    # è¤æ¢—å¤©ç‰›åˆå¹¶ï¼ˆä¿ç•™æˆè™«ï¼‰
    'è¤æ¢—å¤©ç‰›å¹¼è™«': 'è¤æ¢—å¤©ç‰›',
}

print(f"\nğŸ“ è®¡åˆ’åˆå¹¶ {len(merges)} å¯¹å®ä½“")

# ============================================================================
# 2. åº”ç”¨åˆå¹¶
# ============================================================================
print("\nğŸ”„ åº”ç”¨åˆå¹¶...")
merged_count = 0

for old_name, new_name in merges.items():
    # æ£€æŸ¥ä¸¤ä¸ªå®ä½“æ˜¯å¦éƒ½å­˜åœ¨
    if old_name not in concepts_df['entity'].values:
        print(f"  âŠ˜ è·³è¿‡: {old_name} (ä¸å­˜åœ¨)")
        continue
    
    if new_name not in concepts_df['entity'].values:
        print(f"  âš ï¸  ç›®æ ‡å®ä½“ä¸å­˜åœ¨: {new_name}ï¼Œä¿ç•™ {old_name}")
        continue
    
    print(f"  âœ“ {old_name} -> {new_name}")
    
    # æ›´æ–°å…³ç³»
    relationships_df.loc[relationships_df['node_1'] == old_name, 'node_1'] = new_name
    relationships_df.loc[relationships_df['node_2'] == old_name, 'node_2'] = new_name
    
    # åˆ é™¤æ—§å®ä½“
    concepts_df = concepts_df[concepts_df['entity'] != old_name]
    merged_count += 1

print(f"\n  å·²åˆå¹¶: {merged_count} å¯¹")

# ============================================================================
# 3. å»é‡å…³ç³»
# ============================================================================
print("\nğŸ”„ å»é‡å…³ç³»...")
before_dedup = len(relationships_df)

relationships_df = relationships_df.groupby(
    ['node_1', 'node_2', 'edge'], as_index=False
).agg({
    'weight': 'max',
    'source': lambda x: ','.join(sorted(set(','.join(x).split(',')))),
    'chunk_id': 'first'
})

after_dedup = len(relationships_df)
print(f"  âœ“ {before_dedup} -> {after_dedup} (ç§»é™¤ {before_dedup - after_dedup} ä¸ª)")

# ============================================================================
# 4. é‡æ–°åˆ†ç±»å®ä½“
# ============================================================================
print("\nğŸ·ï¸  é‡æ–°åˆ†ç±»å®ä½“...")

reclassifications = {
    # åœ°ç‚¹ç±»
    'å—å¤©é—¨': 'åœ°ç‚¹',
    'å¤©çƒ›å³°': 'åœ°ç‚¹',
    'æ¡ƒèŠ±å³ª': 'åœ°ç‚¹',
    'ç‰æ³‰å¯º': 'åœ°ç‚¹',
    'ç«¹æ—å¯º': 'åœ°ç‚¹',
    'å·´å±±': 'åœ°ç‚¹',
    'å‰æ—': 'åœ°ç‚¹',
    'é»‘é¾™æ±Ÿ': 'åœ°ç‚¹',
    
    # å¯„ä¸»ç±»
    'æ¾æ—': 'å¯„ä¸»',
    'æ‚æœ¨æ—': 'å¯„ä¸»',
    'éº»æ æ—': 'å¯„ä¸»',
    'é’æ¾': 'å¯„ä¸»',
    
    # åª’ä»‹ç±»ï¼ˆæ˜†è™«ç§‘ï¼‰
    'å‰ä¸ç§‘': 'åª’ä»‹',
    'å°è ¢ç§‘': 'åª’ä»‹',
    'ç™½èšç§‘': 'åª’ä»‹',
    
    # å…¶ä»–
    'æ—ä¸š': 'å…¶ä»–',
    'æ—åŒº': 'åœ°ç‚¹',
    'åˆ†å¸ƒåŒº': 'åœ°ç‚¹',
}

reclass_count = 0
for entity, new_category in reclassifications.items():
    if entity in concepts_df['entity'].values:
        old_cat = concepts_df[concepts_df['entity'] == entity]['category'].iloc[0]
        if old_cat != new_category:
            concepts_df.loc[concepts_df['entity'] == entity, 'category'] = new_category
            print(f"  âœ“ {entity:20s}: {old_cat} -> {new_category}")
            reclass_count += 1

print(f"\n  å·²é‡æ–°åˆ†ç±»: {reclass_count} ä¸ª")

# ============================================================================
# 5. ç»Ÿè®¡ç»“æœ
# ============================================================================
print("\nğŸ“Š æœ€ç»ˆç»Ÿè®¡")
print("="*80)

print(f"\næ•°æ®é‡:")
print(f"  å®ä½“: {len(concepts_df)} ä¸ª")
print(f"  å…³ç³»: {len(relationships_df)} ä¸ª")

print(f"\nç±»åˆ«åˆ†å¸ƒ:")
category_counts = concepts_df['category'].value_counts()
for cat, count in category_counts.items():
    pct = count / len(concepts_df) * 100
    print(f"  {cat:15s}: {count:3d} ({pct:5.1f}%)")

print(f"\nå…³ç³»ç±»å‹åˆ†å¸ƒï¼ˆå‰10ï¼‰:")
edge_counts = relationships_df['edge'].value_counts()
for edge, count in edge_counts.head(10).items():
    pct = count / len(relationships_df) * 100
    edge_display = edge if len(edge) <= 30 else edge[:27] + "..."
    print(f"  {edge_display:32s}: {count:3d} ({pct:5.1f}%)")

# ============================================================================
# 6. ä¿å­˜ç»“æœ
# ============================================================================
print("\nğŸ’¾ ä¿å­˜æœ€ç»ˆæ•°æ®...")

concepts_df.to_csv('output/concepts_final.csv', index=False, encoding='utf-8-sig')
relationships_df.to_csv('output/relationships_final.csv', index=False, encoding='utf-8-sig')

print(f"  âœ“ å·²ä¿å­˜: output/concepts_final.csv")
print(f"  âœ“ å·²ä¿å­˜: output/relationships_final.csv")

# ç”ŸæˆNeo4jå¯¼å…¥æ–‡ä»¶
print("\nğŸ”„ ç”ŸæˆNeo4jå¯¼å…¥æ–‡ä»¶...")

nodes_df = pd.DataFrame({
    'id': range(len(concepts_df)),
    'name': concepts_df['entity'],
    'label': concepts_df['category'],
    'importance': concepts_df['importance']
})
nodes_df.to_csv('output/neo4j_import/nodes_final.csv', index=False, encoding='utf-8-sig')

relations_df = pd.DataFrame({
    'start_id': relationships_df['node_1'],
    'relation': relationships_df['edge'],
    'end_id': relationships_df['node_2'],
    'confidence': relationships_df['weight']
})
relations_df.to_csv('output/neo4j_import/relations_final.csv', index=False, encoding='utf-8-sig')

print(f"  âœ“ å·²ä¿å­˜: output/neo4j_import/nodes_final.csv")
print(f"  âœ“ å·²ä¿å­˜: output/neo4j_import/relations_final.csv")

# ä¿å­˜æ‰€æœ‰åˆå¹¶è®°å½•
all_merges = {}
if os.path.exists('output/entity_merges.json'):
    with open('output/entity_merges.json', 'r', encoding='utf-8') as f:
        all_merges = json.load(f)

all_merges.update(merges)

with open('output/all_entity_merges.json', 'w', encoding='utf-8') as f:
    json.dump(all_merges, f, ensure_ascii=False, indent=2)

print(f"  âœ“ åˆå¹¶è®°å½•: output/all_entity_merges.json")

print("\n" + "="*80)
print("âœ“ æœ€ç»ˆä¼˜åŒ–å®Œæˆï¼")
print("="*80)

print("\nğŸ“Œ æ”¹è¿›æ€»ç»“:")
print(f"  â€¢ åˆå¹¶å®ä½“: {merged_count} å¯¹")
print(f"  â€¢ é‡æ–°åˆ†ç±»: {reclass_count} ä¸ª")
print(f"  â€¢ å»é‡å…³ç³»: {before_dedup - after_dedup} ä¸ª")
print(f"  â€¢ æœ€ç»ˆå®ä½“æ•°: {len(concepts_df)}")
print(f"  â€¢ æœ€ç»ˆå…³ç³»æ•°: {len(relationships_df)}")
print(f"  â€¢ 'å…¶ä»–'ç±»åˆ«å æ¯”: {category_counts.get('å…¶ä»–', 0) / len(concepts_df) * 100:.1f}%")

print("\nğŸ“Œ ä¸‹ä¸€æ­¥:")
print("  1. é‡æ–°å¯¼å…¥Neo4j:")
print("     python3 reimport_final_graph.py")
print("  2. å¯è§†åŒ–éªŒè¯:")
print("     python3 visualize_final_graph.py")
